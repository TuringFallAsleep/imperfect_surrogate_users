{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import random \n",
    "import re\n",
    "import math\n",
    "import seaborn as sns\n",
    "from astropy.convolution import convolve\n",
    "from astropy.convolution.kernels import Gaussian1DKernel\n",
    "from astropy.convolution.kernels import Gaussian2DKernel\n",
    "import os\n",
    "from matplotlib.ticker import PercentFormatter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set system parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load entry record updating function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Update_dic_entry_record(dic_entry_record, T_total_temp=0.0, T_key_total_temp=0.0, T_react_w_total_temp=0.0, T_react_s_total_temp=0.0, T_bounded_l_total_temp = 0.0, T_bounded_w_total_temp=0.0, T_bounded_s_total_temp=0.0, T_error_total_temp=0.0, T_interrupt_total_temp=0.0, T_event_total_temp=0.0, N_bounded_l_total_temp=0, N_bounded_w_total_temp=0, N_bounded_s_total_temp=0, KS_total_temp=0, KS_type_total_temp=0, KS_select_total_temp=0, KS_bounded_l_total_temp=0, KS_bounded_w_total_temp=0, KS_bounded_s_total_temp=0, KS_error_total_temp=0, KS_interrup_total_temp=0):\n",
    "\n",
    "    dic_entry_record['T_total'] += T_total_temp\n",
    "    dic_entry_record['T_key_total'] += T_key_total_temp\n",
    "    dic_entry_record['T_react_w_total'] += T_react_w_total_temp\n",
    "    dic_entry_record['T_react_s_total'] += T_react_s_total_temp\n",
    "    dic_entry_record['T_react_total'] += T_react_w_total_temp + T_react_s_total_temp\n",
    "    dic_entry_record['T_bounded_l_total'] += T_bounded_l_total_temp\n",
    "    dic_entry_record['T_bounded_w_total'] += T_bounded_w_total_temp\n",
    "    dic_entry_record['T_bounded_s_total'] += T_bounded_s_total_temp\n",
    "\n",
    "    dic_entry_record['T_error_total'] += T_error_total_temp\n",
    "    dic_entry_record['T_interrupt_total'] += T_interrupt_total_temp\n",
    "    dic_entry_record['T_event_total'] += T_event_total_temp\n",
    "    dic_entry_record['N_bounded_l_total'] += N_bounded_l_total_temp\n",
    "    dic_entry_record['N_bounded_w_total'] += N_bounded_w_total_temp\n",
    "    dic_entry_record['N_bounded_s_total'] += N_bounded_s_total_temp\n",
    "    dic_entry_record['N_bounded_total'] += N_bounded_l_total_temp + N_bounded_w_total_temp + N_bounded_s_total_temp\n",
    "    dic_entry_record['KS_total'] += KS_total_temp\n",
    "    dic_entry_record['KS_type_total'] += KS_type_total_temp\n",
    "    dic_entry_record['KS_select_total'] += KS_select_total_temp\n",
    "    dic_entry_record['KS_bounded_l_total'] += KS_bounded_l_total_temp\n",
    "    dic_entry_record['KS_bounded_w_total'] += KS_bounded_w_total_temp\n",
    "    dic_entry_record['KS_bounded_s_total'] += KS_bounded_s_total_temp\n",
    "    dic_entry_record['KS_error_total'] += KS_error_total_temp\n",
    "    dic_entry_record['KS_interrupt_total'] += KS_interrup_total_temp\n",
    "\n",
    "    return dic_entry_record\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### System output controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOL_PRINT = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set user parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T_key = 0.6 # redefine to suit AAC, time for press the key in seconds \n",
    "# T_react_w = 1.2 # redefine to suit AAC, time for cognitive reactions\n",
    "# T_react_s = 5.42 # redefine to suit AAC, time for cognitive reactions\n",
    "T_key = 0.26 # POK referred data\n",
    "T_react_w = 0.45 # POK referred data\n",
    "T_react_s = 1.87 \n",
    "\n",
    "R_rational = 1 # if random.random() < R_rational, execute optimal action\n",
    "R_error = 0 # if random.random() < R_error, action execution failure\n",
    "\n",
    "R_interrupt = 0.0\n",
    "T_event = 60*random.random()\n",
    "def T_interrupt(T_event): # the probability of the system have correct sentence predictions\n",
    "    a=0.189\n",
    "    c=1.03\n",
    "    return a*math.log(T_event)+c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surrogate user model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check human factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Record_extra_actions(dic_entry_record, dic_rational_record, T_extra_temp, KS_extra_temp):\n",
    "\n",
    "    if dic_rational_record['BOOL_RECORD_ON']:\n",
    "        if dic_rational_record['BOOL_RECORD_S_ON']:\n",
    "            dic_entry_record['T_extra_s'] += T_extra_temp\n",
    "            dic_entry_record['KS_extra_s'] += KS_extra_temp\n",
    "        else:\n",
    "            if dic_rational_record['BOOL_RECORD_W_ON']:\n",
    "                dic_entry_record['T_extra_w'] += T_extra_temp\n",
    "                dic_entry_record['KS_extra_w'] += KS_extra_temp\n",
    "            else:\n",
    "                if dic_rational_record['BOOL_RECORD_L_ON']:\n",
    "                    dic_entry_record['T_extra_l'] += T_extra_temp\n",
    "                    dic_entry_record['KS_extra_l'] += KS_extra_temp \n",
    "\n",
    "    dic_entry_record['T_extra_total'] = dic_entry_record['T_extra_s'] + dic_entry_record['T_extra_w'] + dic_entry_record['T_extra_l']\n",
    "    dic_entry_record['KS_extra_total'] = dic_entry_record['KS_extra_s'] + dic_entry_record['KS_extra_w'] + dic_entry_record['KS_extra_l']\n",
    "    \n",
    "\n",
    "    return dic_entry_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Record_time_saving_from_reactions(dic_entry_record, dic_rational_record, T_react_saving_temp):\n",
    "    if dic_rational_record['BOOL_RECORD_ON']:\n",
    "        if dic_rational_record['BOOL_RECORD_S_ON']:\n",
    "            dic_entry_record['T_react_saving_s'] += T_react_saving_temp\n",
    "        else:\n",
    "            if dic_rational_record['BOOL_RECORD_W_ON']:\n",
    "                dic_entry_record['T_react_saving_w'] += T_react_saving_temp\n",
    "            else:\n",
    "                if dic_rational_record['BOOL_RECORD_L_ON']:\n",
    "                    dic_entry_record['T_react_saving_l'] += T_react_saving_temp\n",
    "\n",
    "    dic_entry_record['T_react_saving_total'] = dic_entry_record['T_react_saving_s'] + dic_entry_record['T_react_saving_w'] + dic_entry_record['T_react_saving_l']\n",
    "    return dic_entry_record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Check_human_factors(dic_entry_record, dic_rational_record, FLAG_TASK, current_letter=None, letter_index=None, current_word=None, word_index=None, current_word_list=None):    \n",
    "    \n",
    "    R_rational = dic_entry_record['R_rational']\n",
    "    R_error = dic_entry_record['R_error']\n",
    "    # R_interrupt = dic_entry_record['R_interrupt']\n",
    "\n",
    "    # L_min_w = dic_entry_record['L_min_w']\n",
    "    # k_look_w = dic_entry_record['k_look_w']\n",
    "    # p_max_w = dic_entry_record['p_max_w']\n",
    "    # L_min_s = dic_entry_record['L_min_s']\n",
    "    # k_look_s = dic_entry_record['k_look_s']\n",
    "    # p_max_s = dic_entry_record['p_max_s']\n",
    "\n",
    "    T_human_factors = 0\n",
    "    KS_human_factors = 0\n",
    "    BOOL_RATIONAL_NEXT = True\n",
    "    # check if the action is rational \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "    rand = random.random()\n",
    "\n",
    "    if rand < R_rational:\n",
    "        # it is rational\n",
    "        BOOL_RATIONAL_NEXT = True\n",
    "        # print(f\"Rational, R_rational = {R_rational}\")\n",
    "    else:\n",
    "        # it is irrational\n",
    "        BOOL_RATIONAL_NEXT = False\n",
    "        # print(f\"Irrational, R_rational = {R_rational}\")\n",
    "\n",
    "    \n",
    "\n",
    "    # check if it is an action execution failure\n",
    "    if random.random() < R_error:\n",
    "        # it is a failure, need correction operations\n",
    "        # press a wrong key\n",
    "        if BOOL_PRINT:\n",
    "            print(\"* Press a wrong letter\")\n",
    "        dic_entry_record = Update_dic_entry_record(dic_entry_record, T_total_temp=T_key, T_key_total_temp=T_key, T_error_total_temp=T_key, KS_total_temp=1, KS_type_total_temp=1, KS_error_total_temp=1)\n",
    "        T_human_factors += T_key\n",
    "        KS_human_factors += 1\n",
    "        if FLAG_TASK=='LETTER' and current_letter != None:\n",
    "            # delete wrong letter\n",
    "            dic_entry_record = Update_dic_entry_record(dic_entry_record, T_total_temp=T_key, T_key_total_temp=T_key, T_error_total_temp=T_key, KS_total_temp=1, KS_type_total_temp=1, KS_error_total_temp=1)\n",
    "            T_human_factors += T_key\n",
    "            KS_human_factors += 1\n",
    "            if BOOL_PRINT:\n",
    "                print(f\"aim letter: {current_letter}\")\n",
    "                print(\"* Delete the wrong letter\")\n",
    "        elif FLAG_TASK=='WORD_PRED' and current_word != None:\n",
    "            # select a wrong word, delect irrelvant letters\n",
    "            KS_this_temp = len(current_word)-letter_index\n",
    "            T_this_temp = T_key*KS_this_temp\n",
    "            dic_entry_record = Update_dic_entry_record(dic_entry_record, T_total_temp=T_this_temp, T_key_total_temp=T_this_temp, T_error_total_temp=T_this_temp, KS_total_temp=KS_this_temp, KS_type_total_temp=KS_this_temp, KS_error_total_temp=KS_this_temp)\n",
    "            T_human_factors += T_key*(len(current_word)-letter_index)\n",
    "            KS_human_factors += len(current_word)-letter_index\n",
    "            if BOOL_PRINT:\n",
    "                print(f\"** Delete {len(current_word)-letter_index} wrong letters\")\n",
    "        elif FLAG_TASK=='SENT_PRED' and current_word_list != None:\n",
    "            # select a wrong sentence, delete irrelvant letters\n",
    "            typed_char = ' '.join(current_word_list[:word_index])\n",
    "            sentence = ' '.join(current_word_list)\n",
    "            KS_this_temp = len(sentence)-len(typed_char)\n",
    "            T_this_temp = T_key*KS_this_temp\n",
    "            dic_entry_record = Update_dic_entry_record(dic_entry_record, T_total_temp=T_this_temp, T_key_total_temp=T_this_temp, T_error_total_temp=T_this_temp, KS_total_temp=KS_this_temp, KS_type_total_temp=KS_this_temp, KS_error_total_temp=KS_this_temp)\n",
    "            T_human_factors += T_key*(len(sentence)-len(typed_char))\n",
    "            KS_human_factors += len(sentence)-len(typed_char)\n",
    "            if BOOL_PRINT:\n",
    "                print(f\"*** Delete {len(sentence)-len(typed_char)} wrong letters\")\n",
    "    else:\n",
    "        #  it is not a failure\n",
    "        pass\n",
    "\n",
    "\n",
    "    return dic_entry_record, dic_rational_record, T_human_factors, KS_human_factors, BOOL_RATIONAL_NEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter current word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Enter_current_word(dic_entry_record, dic_rational_record, word_list, word):\n",
    "\n",
    "    L_min_w = dic_entry_record['L_min_w']\n",
    "    k_look_w = dic_entry_record['k_look_w']\n",
    "    p_max_w = dic_entry_record['p_max_w']\n",
    "\n",
    "\n",
    "    next_word = \"\"\n",
    "\n",
    "    if BOOL_PRINT:\n",
    "        print(f\"Entering current word: {word}\")\n",
    "    BOOL_TYPING = True\n",
    "    BOOL_WORD_SELECTED = False\n",
    "    T_current_word = 0\n",
    "    KS_current_word = 0\n",
    "    current_char_index = 0\n",
    "    if len(word) < L_min_w:\n",
    "        if BOOL_PRINT:\n",
    "            print(f\"Current word \\\"{word}\\\" is too short to use word pred\")\n",
    "        # type out all letters without prediction with the space\n",
    "        # check human factors\n",
    "        for i, letter in enumerate(word):\n",
    "            dic_entry_record, dic_rational_record, T_temp, KS_temp, BOOL_RATIONAL_L_min_w_True = Check_human_factors(dic_entry_record, dic_rational_record, FLAG_TASK='LETTER', current_letter=letter) # BOOL_RATIONAL\n",
    "            T_current_word += T_temp\n",
    "            KS_current_word += KS_temp\n",
    "            # press the expected key, same for rational and irrational\n",
    "            if BOOL_RATIONAL_L_min_w_True==True or BOOL_RATIONAL_L_min_w_True==False:\n",
    "                dic_entry_record = Update_dic_entry_record(dic_entry_record, T_total_temp=T_key, T_key_total_temp=T_key, KS_total_temp=1, KS_type_total_temp=1)\n",
    "                T_current_word += T_key\n",
    "                KS_current_word += 1\n",
    "                current_char_index += 1\n",
    "                if BOOL_PRINT:\n",
    "                    print(f\"-> KS_total={dic_entry_record['KS_total']}. Type letter: {letter}. Same operation for rational and irrational cases\")\n",
    "        # press space\n",
    "        dic_entry_record = Update_dic_entry_record(dic_entry_record, T_total_temp=T_key, T_key_total_temp=T_key, KS_total_temp=1, KS_type_total_temp=1)\n",
    "        T_current_word += T_key\n",
    "        KS_current_word += 1\n",
    "        \n",
    "        if BOOL_PRINT:\n",
    "            print(f\"-> KS_total={dic_entry_record['KS_total']}. Press space to finish the word\")\n",
    "    else:\n",
    "        if BOOL_PRINT:\n",
    "            print(f\"Current word \\\"{word}\\\" is long enough to use word pred\")\n",
    "        # could use prediction\n",
    "        # check human factors before typing the first key\n",
    "        dic_entry_record, dic_rational_record, T_temp, KS_temp, BOOL_RATIONAL_L_min_w_False = Check_human_factors(dic_entry_record, dic_rational_record, FLAG_TASK='LETTER',current_letter=word[current_char_index])\n",
    "        T_current_word += T_temp\n",
    "        KS_current_word += KS_temp\n",
    "        # press the initial letter of the word\n",
    "        if BOOL_RATIONAL_L_min_w_False==True or BOOL_RATIONAL_L_min_w_False==False:\n",
    "            dic_entry_record = Update_dic_entry_record(dic_entry_record, T_total_temp=T_key, T_key_total_temp=T_key, KS_total_temp=1, KS_type_total_temp=1)\n",
    "            T_current_word += T_key\n",
    "            # current_char_index = 0\n",
    "            KS_current_word += 1\n",
    "            if BOOL_PRINT:\n",
    "                print(f\"-> KS_total={dic_entry_record['KS_total']}. Type the initial letter: {word[current_char_index]}. Same operation for rational and irrational cases\")\n",
    "            current_char_index += 1\n",
    "        while BOOL_TYPING:\n",
    "            # start from the second letter\n",
    "            if current_char_index < len(word): \n",
    "                # not finish\n",
    "                if current_char_index+1 > p_max_w:\n",
    "                    # type out remainig letters in word\n",
    "                    if BOOL_PRINT:\n",
    "                        print(\"Word perseverance reached, type out remaining letters in the word\")\n",
    "                    for letter in word[current_char_index:]:\n",
    "                        dic_entry_record, dic_rational_record, T_temp, KS_temp, BOOL_RATIONAL_p_max_w_True = Check_human_factors(dic_entry_record, dic_rational_record, FLAG_TASK='LETTER',current_letter=letter)\n",
    "                        T_current_word += T_temp\n",
    "                        KS_current_word += KS_temp\n",
    "                        if BOOL_RATIONAL_p_max_w_True==True or BOOL_RATIONAL_p_max_w_True==False:\n",
    "                            dic_entry_record = Update_dic_entry_record(dic_entry_record, T_total_temp=T_key, T_key_total_temp=T_key, KS_total_temp=1, KS_type_total_temp=1)\n",
    "                            T_current_word += T_key\n",
    "                            KS_current_word += 1\n",
    "                            if BOOL_PRINT:\n",
    "                                print(f\"-> KS_total={dic_entry_record['KS_total']}. Type letter: {letter}. Same operation for rational and irrational cases\")\n",
    "                            current_char_index += 1\n",
    "                    # Press space \n",
    "                    dic_entry_record = Update_dic_entry_record(dic_entry_record, T_total_temp=T_key, T_key_total_temp=T_key, KS_total_temp=1, KS_type_total_temp=1)\n",
    "                    T_current_word += T_key\n",
    "                    KS_current_word += 1\n",
    "                    if BOOL_PRINT:\n",
    "                        print(f\"-> KS_total={dic_entry_record['KS_total']}. Press space to finish the word\")\n",
    "\n",
    "                    break\n",
    "                else:\n",
    "                    if BOOL_PRINT:\n",
    "                        print(\"Haven't reached word perseverance yet\")\n",
    "                    if current_char_index+1 > k_look_w: # could start to check word pred\n",
    "                        if BOOL_PRINT:\n",
    "                            print(\"Reached word type-then-look, could use word pred\")\n",
    "\n",
    "                        dic_entry_record, dic_rational_record, T_temp, KS_temp, BOOL_RATIONAL_k_look_w_True = Check_human_factors(dic_entry_record, dic_rational_record, FLAG_TASK='WORD_PRED', letter_index=current_char_index, current_word=word)\n",
    "                        T_current_word += T_temp\n",
    "                        KS_current_word += KS_temp\n",
    "                        if BOOL_RATIONAL_k_look_w_True:\n",
    "                            if BOOL_PRINT:\n",
    "                                print(\"A rational action, check current word pred\")\n",
    "                            dic_entry_record = Update_dic_entry_record(dic_entry_record, T_total_temp=T_react_w, T_react_w_total_temp=T_react_w)\n",
    "                            T_current_word += T_react_w\n",
    "\n",
    "                            if random.random() < P_pred_w_c:\n",
    "                            # current word pred obtained\n",
    "                            # obtain pred word\n",
    "                                if BOOL_PRINT:\n",
    "                                    print(\"Current word pred obtained.\")\n",
    "                                \n",
    "                                # select word pred\n",
    "                                dic_entry_record = Update_dic_entry_record(dic_entry_record, T_total_temp=T_key, T_key_total_temp=T_key, KS_total_temp=1, KS_select_total_temp=1)\n",
    "                                T_current_word += T_key\n",
    "                                KS_current_word += 1\n",
    "                                current_char_index = len(word)-1\n",
    "                                BOOL_WORD_SELECTED = True\n",
    "                                if BOOL_PRINT:\n",
    "                                    print(f\"-> KS_total={dic_entry_record['KS_total']}. A rational action, select word {word}\")\n",
    "                                break\n",
    "                            else:\n",
    "                            # not obtain word pred, type next letter\n",
    "                                BOOL_WORD_SELECTED = False\n",
    "                                dic_entry_record, dic_rational_record, T_temp, KS_temp, BOOL_RATIONAL_P_pred_w_c_False = Check_human_factors(dic_entry_record, dic_rational_record, FLAG_TASK='LETTER', current_letter=word[current_char_index])\n",
    "                                T_current_word += T_temp\n",
    "                                KS_current_word += KS_temp\n",
    "                                if BOOL_RATIONAL_P_pred_w_c_False==True or BOOL_RATIONAL_P_pred_w_c_False==False:\n",
    "                                    dic_entry_record = Update_dic_entry_record(dic_entry_record, T_total_temp=T_key, T_key_total_temp=T_key, KS_total_temp=1, KS_type_total_temp=1)\n",
    "                                    T_current_word += T_key\n",
    "                                    KS_current_word += 1\n",
    "                                    if BOOL_PRINT:\n",
    "                                        print(f\"-> KS_total={dic_entry_record['KS_total']}. Not obtain word pred, type next letter: {word[current_char_index]}. Same operation for rational and irrational cases\")\n",
    "                                    current_char_index += 1 \n",
    "\n",
    "                                    if current_char_index == len(word):\n",
    "                                        # press space\n",
    "                                        dic_entry_record = Update_dic_entry_record(dic_entry_record, T_total_temp=T_key, T_key_total_temp=T_key, KS_total_temp=1, KS_type_total_temp=1)\n",
    "                                        T_current_word += T_key\n",
    "                                        KS_current_word += 1\n",
    "                                        if BOOL_PRINT:\n",
    "                                            print(f\"-> KS_total={dic_entry_record['KS_total']}. Press space to finish the word\")\n",
    "\n",
    "                        else:\n",
    "                            # Irrational, type next letter without checking the word prediction.\n",
    "                            if BOOL_PRINT:\n",
    "                                print(f\"-> KS_total={dic_entry_record['KS_total']+1}. An irrational action: letter level. not check word pred, type next letter {word[current_char_index]}\")\n",
    "                            if dic_rational_record['BOOL_RECORD_S_ON'] == False and dic_rational_record['BOOL_RECORD_W_ON'] == False:\n",
    "                                dic_rational_record['BOOL_RECORD_L_ON'] = True\n",
    "                                dic_rational_record['BOOL_RECORD_ON'] = False\n",
    "                            # print(f\"BOOL_RECORD_S_ON: {dic_rational_record['BOOL_RECORD_S_ON']} - {dic_entry_record['KS_extra_s']}, BOOL_RECORD_W_ON: {dic_rational_record['BOOL_RECORD_W_ON']} - {dic_entry_record['KS_extra_w']}, BOOL_RECORD_L_ON: {dic_rational_record['BOOL_RECORD_L_ON']} - {dic_entry_record['KS_extra_l']}\")\n",
    "\n",
    "                            dic_entry_record = Update_dic_entry_record(dic_entry_record, T_total_temp=T_key, T_key_total_temp=T_key, N_bounded_l_total_temp=1, T_bounded_l_total_temp=T_key, KS_total_temp=1, KS_type_total_temp=1, KS_bounded_l_total_temp=1)\n",
    "                            if dic_rational_record['BOOL_RECORD_S_ON'] == False and dic_rational_record['BOOL_RECORD_W_ON'] == False:\n",
    "                                dic_rational_record['BOOL_RECORD_ON'] = True\n",
    "                            if current_char_index+1 < len(word): \n",
    "                                # if the pred is last letter, then there is an action anyway - either click letter or choose pred, so no extra action\n",
    "                                dic_entry_record = Record_extra_actions(dic_entry_record, dic_rational_record, T_extra_temp=T_key, KS_extra_temp=1)\n",
    "                            T_current_word += T_key\n",
    "                            KS_current_word += 1\n",
    "                            # Update the time saving\n",
    "                            dic_entry_record = Record_time_saving_from_reactions(dic_entry_record, dic_rational_record, T_react_saving_temp=T_react_w)\n",
    "                            \n",
    "                            current_char_index += 1\n",
    "                            if dic_rational_record['BOOL_RECORD_S_ON'] == False and dic_rational_record['BOOL_RECORD_W_ON'] == False:\n",
    "                                dic_rational_record['BOOL_RECORD_ON'] = False\n",
    "                                dic_rational_record['BOOL_RECORD_L_ON'] = False\n",
    "                            # print(f\"BOOL_RECORD_S_ON: {dic_rational_record['BOOL_RECORD_S_ON']} - {dic_entry_record['KS_extra_s']}, BOOL_RECORD_W_ON: {dic_rational_record['BOOL_RECORD_W_ON']} - {dic_entry_record['KS_extra_w']}, BOOL_RECORD_L_ON: {dic_rational_record['BOOL_RECORD_L_ON']} - {dic_entry_record['KS_extra_l']}\")\n",
    "\n",
    "                            \n",
    "                            if current_char_index == len(word):\n",
    "                                # press space\n",
    "                                dic_entry_record = Update_dic_entry_record(dic_entry_record, T_total_temp=T_key, T_key_total_temp=T_key, KS_total_temp=1, KS_type_total_temp=1)\n",
    "                                T_current_word += T_key\n",
    "                                KS_current_word += 1\n",
    "                                if BOOL_PRINT:\n",
    "                                    print(f\"-> KS_total={dic_entry_record['KS_total']}. Press space to finish the word\")\n",
    "\n",
    "                    else:\n",
    "                        # do not check word pred, just type next letter\n",
    "                        dic_entry_record, dic_rational_record, T_temp, KS_temp, BOOL_RATIONAL_k_look_w_False = Check_human_factors(dic_entry_record, dic_rational_record, FLAG_TASK='LETTER', current_letter=word[current_char_index])\n",
    "                        T_current_word += T_temp\n",
    "                        KS_current_word += KS_temp\n",
    "                        if BOOL_RATIONAL_k_look_w_False==True or BOOL_RATIONAL_k_look_w_False==False:\n",
    "                            dic_entry_record = Update_dic_entry_record(dic_entry_record, T_total_temp=T_key, T_key_total_temp=T_key, KS_total_temp=1, KS_type_total_temp=1)\n",
    "                            T_current_word += T_key\n",
    "                            KS_current_word += 1\n",
    "                            if BOOL_PRINT:\n",
    "                                print(f\"-> KS_total={dic_entry_record['KS_total']}. Not reach word type-then-look, just type next letter: {word[current_char_index]}. Same operation for rational and irrational cases\")\n",
    "                            current_char_index += 1\n",
    "                            \n",
    "                            if current_char_index == len(word):\n",
    "                                # press space\n",
    "                                dic_entry_record = Update_dic_entry_record(dic_entry_record, T_total_temp=T_key, T_key_total_temp=T_key, KS_total_temp=1, KS_type_total_temp=1)\n",
    "                                T_current_word += T_key\n",
    "                                KS_current_word += 1\n",
    "                                if BOOL_PRINT:\n",
    "                                    print(f\"-> KS_total={dic_entry_record['KS_total']}. Press space to finish the word\")\n",
    "            else:\n",
    "                # current word is finished\n",
    "                if BOOL_PRINT:\n",
    "                    print(f\"Current word {word} is finished\")\n",
    "                BOOL_TYPING = False\n",
    "    # Assign next word\n",
    "    if word_list.index(word)+1 == len(word_list):\n",
    "        next_word = \"\"\n",
    "        if BOOL_WORD_SELECTED == False:\n",
    "            # Remove the space after the final word\n",
    "            if BOOL_PRINT:\n",
    "                print(\"Last word typed, remove the space after the final word\")\n",
    "            T_current_word -= T_key\n",
    "            KS_current_word -= 1\n",
    "            # Special dic_entry_record\n",
    "            dic_entry_record['T_total'] -= T_key\n",
    "            dic_entry_record['T_key_total'] -= T_key\n",
    "            dic_entry_record['KS_total'] -= 1\n",
    "            dic_entry_record['KS_type_total'] -= 1\n",
    "    else:\n",
    "        next_word = word_list[word_list.index(word)+1]\n",
    "                \n",
    "    return dic_entry_record, dic_rational_record, next_word, T_current_word, KS_current_word, BOOL_WORD_SELECTED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check sentence finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Check_sentence_finish(dic_entry_record, dic_rational_record, current_word, word_list):\n",
    "    # Start from 2nd word\n",
    "\n",
    "    L_min_s = dic_entry_record['L_min_s']\n",
    "    k_look_s = dic_entry_record['k_look_s']\n",
    "    p_max_s = dic_entry_record['p_max_s']\n",
    "\n",
    "    T_sentence = 0\n",
    "    KS_sentence = 0\n",
    "    next_word = ''\n",
    "    BOOL_SENTENCE_UNFINISH = True\n",
    "\n",
    "    # if current_word == word_list[0]:\n",
    "    #     if len(word_list) > 1:\n",
    "    #         current_word = word_list[1]\n",
    "\n",
    "    # find word selected, it will be typed again\n",
    "    if current_word == word_list[-1]: #  and current_word != word_list[0]\n",
    "        if BOOL_PRINT:\n",
    "            print(\">>> Sentence finished\")\n",
    "            print(\"------------------------------------------------------------\")\n",
    "        BOOL_SENTENCE_UNFINISH = False\n",
    "    else:\n",
    "        if len(word_list) < L_min_s:\n",
    "            # Do not use sentence pred, Type next word. \n",
    "            if BOOL_PRINT:\n",
    "                print(\"This sentence is too short to use sentence pred\")\n",
    "            dic_entry_record, dic_rational_record, T_temp, KS_temp, next_word, BOOL_SENTENCE_UNFINISH = Enter_next_word(dic_entry_record, dic_rational_record, current_word, word_list)\n",
    "            T_sentence += T_temp\n",
    "            KS_sentence += KS_temp\n",
    "        else: \n",
    "            if BOOL_PRINT:\n",
    "                print(\"This sentence is long enough to use sentence pred\")\n",
    "            current_word_index = Find_current_word_index(current_word, word_list)\n",
    "            # this may differ from generation and retrieval\n",
    "            if current_word_index+1 > p_max_s:\n",
    "                # Do not use sentence pred, type next word out\n",
    "                if BOOL_PRINT:\n",
    "                    print(\"Sentence perseverance reached, not use sentence pred, type out next word in the sentence.\")\n",
    "                dic_entry_record, dic_rational_record, T_temp, KS_temp, next_word, BOOL_SENTENCE_UNFINISH = Enter_next_word(dic_entry_record, dic_rational_record, current_word, word_list)\n",
    "                T_sentence += T_temp\n",
    "                KS_sentence += KS_temp\n",
    "            else: \n",
    "                if BOOL_PRINT:\n",
    "                    print(\"Haven't reached sentence perseverance yet, could use sentence pred.\")\n",
    "                if current_word_index+1 > k_look_s:\n",
    "                    if BOOL_PRINT:\n",
    "                        print(\"Reached sentence type-then-look, could use sentence pred\")\n",
    "                    dic_entry_record, dic_rational_record, T_temp, KS_temp, BOOL_RATIONAL_k_look_s_True = Check_human_factors(dic_entry_record, dic_rational_record, FLAG_TASK='SENT_PRED', current_word=current_word, current_word_list=word_list)\n",
    "                    T_sentence += T_temp\n",
    "                    KS_sentence += KS_temp\n",
    "                    if BOOL_RATIONAL_k_look_s_True:\n",
    "                        dic_entry_record = Update_dic_entry_record(dic_entry_record, T_react_s_total_temp=T_react_s)        \n",
    "                        T_sentence += T_react_s\n",
    "                        if random.random() < P_pred_s:\n",
    "                            if BOOL_PRINT:\n",
    "                                print(\"Obtained sentence pred\")\n",
    "                            # obtained sentence pred and click to select \n",
    "                            # dic_entry_record, dic_rational_record, T_temp, KS_temp, BOOL_RATIONAL_P_pred_s_True = Check_human_factors(dic_entry_record, dic_rational_record, FLAG_TASK='SENT_PRED', current_word=current_word, current_word_list=word_list)\n",
    "                            # T_sentence += T_temp\n",
    "                            # KS_sentence += KS_temp\n",
    "                            # if BOOL_RATIONAL_P_pred_s_True:\n",
    "                                # check sentence pred\n",
    "                            \n",
    "                            dic_entry_record = Update_dic_entry_record(dic_entry_record, T_total_temp=T_key, T_key_total_temp=T_key, KS_total_temp=1, KS_select_total_temp=1) \n",
    "                            T_sentence += T_key   \n",
    "                            KS_sentence += 1 \n",
    "                            if BOOL_PRINT:\n",
    "                                print(f\"->>> KS_total={dic_entry_record['KS_total']}. A rational action, select sentence pred\")\n",
    "                            \n",
    "                            current_word_index = len(word_list)-1\n",
    "                            if BOOL_PRINT:\n",
    "                                print(\"Sentence finished\")\n",
    "                                print(\"------------------------------------------------------------\")\n",
    "                            BOOL_SENTENCE_UNFINISH = False    \n",
    "                        else:\n",
    "                            # didn't find satisfying sentence, entry next word \n",
    "                            if BOOL_PRINT:\n",
    "                                print(\"Not obtain sentence pred, entry next word\")\n",
    "                            dic_entry_record, dic_rational_record, T_temp, KS_temp, next_word, BOOL_SENTENCE_UNFINISH = Enter_next_word(dic_entry_record, dic_rational_record, current_word, word_list)  \n",
    "                            T_sentence += T_temp\n",
    "                            KS_sentence += KS_temp\n",
    "                    else:\n",
    "                        dic_rational_record['BOOL_RECORD_S_ON'] = True\n",
    "                        dic_rational_record['BOOL_RECORD_W_ON'] = False\n",
    "                        dic_rational_record['BOOL_RECORD_L_ON'] = False\n",
    "                        dic_rational_record['BOOL_RECORD_ON'] = False\n",
    "                        if BOOL_PRINT:\n",
    "                            print(\"An irrational action: sentence level. not check sentence pred, type next word\")\n",
    "                            # print(f\"BOOL_RECORD_S_ON: {dic_rational_record['BOOL_RECORD_S_ON']} - {dic_entry_record['KS_extra_s']}, BOOL_RECORD_W_ON: {dic_rational_record['BOOL_RECORD_W_ON']} - {dic_entry_record['KS_extra_w']}, BOOL_RECORD_L_ON: {dic_rational_record['BOOL_RECORD_L_ON']} - {dic_entry_record['KS_extra_l']}\")\n",
    "                        \n",
    "                        dic_entry_record, dic_rational_record, T_temp, KS_temp, next_word, BOOL_SENTENCE_UNFINISH = Enter_next_word(dic_entry_record, dic_rational_record, current_word, word_list)\n",
    "                        dic_entry_record = Update_dic_entry_record(dic_entry_record, N_bounded_s_total_temp=1, T_bounded_s_total_temp=T_temp, KS_bounded_s_total_temp=KS_temp)\n",
    "                        dic_rational_record['BOOL_RECORD_ON'] = True\n",
    "                        dic_entry_record = Record_extra_actions(dic_entry_record, dic_rational_record, T_extra_temp=T_temp-T_key, KS_extra_temp=KS_temp-1) # there is a choose action that needs to be subtracted\n",
    "                        T_sentence += T_temp\n",
    "                        KS_sentence += KS_temp\n",
    "                        # Update the time saving\n",
    "                        dic_entry_record = Record_time_saving_from_reactions(dic_entry_record, dic_rational_record, T_react_saving_temp=T_react_s)\n",
    "                        dic_rational_record['BOOL_RECORD_S_ON'] = False\n",
    "                        dic_rational_record['BOOL_RECORD_ON'] = False\n",
    "                        \n",
    "                        # if BOOL_PRINT:\n",
    "                            # print(f\"BOOL_RECORD_S_ON: {dic_rational_record['BOOL_RECORD_S_ON']} - {dic_entry_record['KS_extra_s']}, BOOL_RECORD_W_ON: {dic_rational_record['BOOL_RECORD_W_ON']} - {dic_entry_record['KS_extra_w']}, BOOL_RECORD_L_ON: {dic_rational_record['BOOL_RECORD_L_ON']} - {dic_entry_record['KS_extra_l']}\")\n",
    "                            # print(\"Sentence finished - 2\")\n",
    "                            # print(\"------------------------------------------------------------\")\n",
    "                        current_word_index = Find_current_word_index(current_word, word_list) \n",
    "                        if next_word == '':\n",
    "                            BOOL_SENTENCE_UNFINISH = False\n",
    "                else:\n",
    "                    # do not check sentence pred, just entry next word\n",
    "                    if BOOL_PRINT:\n",
    "                        print(\"Not reach sentence type-then-look, type next word\")\n",
    "                    dic_entry_record, dic_rational_record, T_temp, KS_temp, next_word, BOOL_SENTENCE_UNFINISH = Enter_next_word(dic_entry_record, dic_rational_record, current_word, word_list)\n",
    "                    T_sentence += T_temp\n",
    "                    KS_sentence += KS_temp\n",
    "    \n",
    "    if next_word == '':\n",
    "        BOOL_SENTENCE_UNFINISH = False\n",
    "\n",
    "    return dic_entry_record, dic_rational_record, T_sentence, KS_sentence, next_word, BOOL_SENTENCE_UNFINISH "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_current_word_index(current_word, word_list):\n",
    "    current_word_index = 0\n",
    "    i = 0\n",
    "    for i, word in enumerate(word_list):\n",
    "        # assume all words are different in a sentence\n",
    "        if current_word == word:\n",
    "            current_word_index = i\n",
    "            break\n",
    "    return current_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Enter_next_word(dic_entry_record, dic_rational_record, current_word, word_list):\n",
    "\n",
    "    \n",
    "    current_word_index = Find_current_word_index(current_word, word_list)\n",
    "\n",
    "    T_next_word = 0\n",
    "    KS_next_word = 0\n",
    "    # look at word pred\n",
    "    BOOL_SENTENCE_UNFINISH = True\n",
    "\n",
    "    dic_entry_record, dic_rational_record, T_temp, KS_temp, BOOL_RATIONAL_check_word_pred = Check_human_factors(dic_entry_record, dic_rational_record, FLAG_TASK='WORD_PRED', letter_index=0, current_word=current_word)\n",
    "    T_next_word += T_temp\n",
    "    KS_next_word += KS_temp\n",
    "    if BOOL_RATIONAL_check_word_pred:\n",
    "        if BOOL_PRINT:\n",
    "            print(\"A rational action, check word pred\")\n",
    "        dic_entry_record = Update_dic_entry_record(dic_entry_record, T_total_temp=T_react_w, T_react_w_total_temp=T_react_w)\n",
    "        T_next_word += T_react_w\n",
    "\n",
    "        if random.random() < P_pred_w_n:\n",
    "            if BOOL_PRINT:\n",
    "                print(\"Obtained next word pred\")\n",
    "            # dic_entry_record, dic_rational_record, T_temp, KS_temp, BOOL_RATIONAL_P_pred_w_n = Check_human_factors(dic_entry_record, dic_rational_record, FLAG_TASK='LETTER', current_letter=' ')\n",
    "            # T_next_word += T_temp\n",
    "            # KS_next_word += KS_temp\n",
    "            # if BOOL_RATIONAL_P_pred_w_n:\n",
    "                # next word is obtained, click to select\n",
    "\n",
    "            dic_entry_record = Update_dic_entry_record(dic_entry_record, T_total_temp=T_key, T_key_total_temp=T_key, KS_total_temp=1, KS_select_total_temp=1)\n",
    "            T_next_word += T_key\n",
    "            KS_next_word += 1\n",
    "            current_word_index += 1\n",
    "            current_word = word_list[current_word_index]\n",
    "            if BOOL_PRINT:\n",
    "                print(f\"-> KS_total={dic_entry_record['KS_total']}. Select next word: {current_word}. A rational action\")\n",
    "            dic_entry_record, dic_rational_record, T_temp, KS_temp, current_word, BOOL_SENTENCE_UNFINISH = Check_sentence_finish(dic_entry_record, dic_rational_record, current_word, word_list)\n",
    "            T_next_word += T_temp\n",
    "            KS_next_word += KS_temp \n",
    "            \n",
    "            # else:\n",
    "                \n",
    "        else:\n",
    "            # next word is not obtained, entry next \"current word\"\n",
    "            if BOOL_PRINT:\n",
    "                print(\"Not obtained next word pred, type letters of the next word\")\n",
    "            current_word_index += 1\n",
    "            current_word = word_list[current_word_index]\n",
    "            dic_entry_record, dic_rational_record, next_word, T_temp, KS_temp, BOOL_WORD_SELECTED = Enter_current_word(dic_entry_record, dic_rational_record, word_list, current_word) \n",
    "            T_next_word += T_temp\n",
    "            KS_next_word += KS_temp\n",
    "            if current_word == word_list[-1]:\n",
    "                BOOL_SENTENCE_UNFINISH = False\n",
    "    else:\n",
    "        if BOOL_PRINT:\n",
    "            print(\"An irrational action: word level. not check word pred, type letters of the next word\")\n",
    "        if dic_rational_record['BOOL_RECORD_S_ON'] == False:\n",
    "            dic_rational_record['BOOL_RECORD_W_ON'] = True\n",
    "            dic_rational_record['BOOL_RECORD_L_ON'] = False\n",
    "            dic_rational_record['BOOL_RECORD_ON'] = False\n",
    "        # print(f\"BOOL_RECORD_S_ON: {dic_rational_record['BOOL_RECORD_S_ON']} - {dic_entry_record['KS_extra_s']}, BOOL_RECORD_W_ON: {dic_rational_record['BOOL_RECORD_W_ON']} - {dic_entry_record['KS_extra_w']}, BOOL_RECORD_L_ON: {dic_rational_record['BOOL_RECORD_L_ON']} - {dic_entry_record['KS_extra_l']}\")\n",
    "\n",
    "        current_word_index += 1\n",
    "        current_word = word_list[current_word_index]\n",
    "        dic_entry_record, dic_rational_record, next_word, T_temp, KS_temp, BOOL_WORD_SELECTED = Enter_current_word(dic_entry_record, dic_rational_record, word_list, current_word) \n",
    "        dic_entry_record = Update_dic_entry_record(dic_entry_record, N_bounded_w_total_temp=1, T_bounded_w_total_temp=T_temp, KS_bounded_w_total_temp=KS_temp)\n",
    "        if dic_rational_record['BOOL_RECORD_S_ON'] == False:\n",
    "            dic_rational_record['BOOL_RECORD_ON'] = True\n",
    "        dic_entry_record = Record_extra_actions(dic_entry_record, dic_rational_record, T_extra_temp=T_temp-T_key, KS_extra_temp=KS_temp-1) # there is a choose pred action that needs to be subtracted\n",
    "        T_next_word += T_temp\n",
    "        KS_next_word += KS_temp\n",
    "        # Update the time saving\n",
    "        dic_entry_record = Record_time_saving_from_reactions(dic_entry_record, dic_rational_record, T_react_saving_temp=T_react_w)\n",
    "        dic_rational_record['BOOL_RECORD_W_ON'] = False\n",
    "        if dic_rational_record['BOOL_RECORD_S_ON'] == False:\n",
    "            dic_rational_record['BOOL_RECORD_ON'] = False\n",
    "            \n",
    "    return dic_entry_record, dic_rational_record, T_next_word, KS_next_word, current_word, BOOL_SENTENCE_UNFINISH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type one sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Type_one_sentence(sentence, L_min_w, k_look_w, p_max_w, L_min_s, k_look_s, p_max_s, R_rational=1, R_error=0, R_interrupt=0, T_event=5):\n",
    "\n",
    "    T_total = 0\n",
    "    T_key_total = 0\n",
    "    T_react_w_total = 0\n",
    "    T_react_s_total = 0\n",
    "    T_react_total = 0\n",
    "    T_bounded_l_total = 0\n",
    "    T_bounded_w_total = 0\n",
    "    T_bounded_s_total = 0\n",
    "    T_error_total = 0\n",
    "    T_interrupt_total = 0\n",
    "\n",
    "    T_extra_s = 0\n",
    "    T_extra_w = 0\n",
    "    T_extra_l = 0\n",
    "    T_extra_total = 0\n",
    "    T_react_saving_s = 0\n",
    "    T_react_saving_w = 0\n",
    "    T_react_saving_l = 0\n",
    "    T_react_saving_total = 0\n",
    "    T_net_extra = 0\n",
    "\n",
    "    N_bounded_l_total = 0\n",
    "    N_bounded_w_total = 0\n",
    "    N_bounded_s_total = 0\n",
    "    N_bounded_total = 0\n",
    "    T_event_total = 0\n",
    "    \n",
    "    KS_total = 0\n",
    "    KS_type_total = 0\n",
    "    KS_select_total = 0\n",
    "    KS_bounded_l_total = 0\n",
    "    KS_bounded_w_total = 0\n",
    "    KS_bounded_s_total = 0\n",
    "    KS_error_total = 0\n",
    "    KS_interrupt_total = 0\n",
    "    KS_extra_s = 0\n",
    "    KS_extra_w = 0\n",
    "    KS_extra_l = 0\n",
    "    KS_extra_total = 0\n",
    "\n",
    "    dic_entry_record = {\n",
    "        \"L_min_w\": float(L_min_w),\n",
    "        \"k_look_w\": float(k_look_w),\n",
    "        \"p_max_w\": float(p_max_w),\n",
    "        \"L_min_s\": float(L_min_s),\n",
    "        \"k_look_s\": float(k_look_s),\n",
    "        \"p_max_s\": float(p_max_s),\n",
    "        \n",
    "        'R_rational': float(R_rational),\n",
    "        'R_error': float(R_error),\n",
    "        'R_interrupt': float(R_interrupt),\n",
    "        'T_event': float(T_event),\n",
    "\n",
    "        \"T_total\": float(T_total),\n",
    "        \"T_key_total\": float(T_key_total),\n",
    "        \"T_react_w_total\": float(T_react_w_total),\n",
    "        \"T_react_s_total\": float(T_react_s_total),\n",
    "        \"T_react_total\": float(T_react_total),\n",
    "        \"T_bounded_l_total\": float(T_bounded_l_total),\n",
    "        \"T_bounded_w_total\": float(T_bounded_w_total),\n",
    "        \"T_bounded_s_total\": float(T_bounded_s_total),\n",
    "        \"T_error_total\": float(T_error_total),\n",
    "        \"T_interrupt_total\": float(T_interrupt_total),\n",
    "        \"T_extra_s\": float(T_extra_s),\n",
    "        \"T_extra_w\": float(T_extra_w),\n",
    "        \"T_extra_l\": float(T_extra_l),\n",
    "        \"T_extra_total\": float(T_extra_total),\n",
    "        \"T_react_saving_s\": float(T_react_saving_s),\n",
    "        \"T_react_saving_w\": float(T_react_saving_w),\n",
    "        \"T_react_saving_l\": float(T_react_saving_l),\n",
    "        \"T_react_saving_total\": float(T_react_saving_total),\n",
    "        \"T_net_extra\": float(T_net_extra),\n",
    "\n",
    "\n",
    "        \"N_bounded_l_total\": int(N_bounded_l_total),\n",
    "        \"N_bounded_w_total\": int(N_bounded_w_total),\n",
    "        \"N_bounded_s_total\": int(N_bounded_s_total),\n",
    "        \"N_bounded_total\": int(N_bounded_total),\n",
    "        \"T_event_total\": float(T_event_total),\n",
    "\n",
    "        \"KS_total\": int(KS_total),\n",
    "        \"KS_type_total\": int(KS_type_total),\n",
    "        \"KS_select_total\": int(KS_select_total),\n",
    "        \"KS_bounded_l_total\": int(KS_bounded_l_total),\n",
    "        \"KS_bounded_w_total\": int(KS_bounded_w_total),\n",
    "        \"KS_bounded_s_total\": int(KS_bounded_s_total),\n",
    "        \"KS_error_total\": int(KS_error_total),\n",
    "        \"KS_interrupt_total\": int(KS_interrupt_total),\n",
    "        \"KS_extra_s\": int(KS_extra_s),\n",
    "        \"KS_extra_w\": int(KS_extra_w),\n",
    "        \"KS_extra_l\": int(KS_extra_l),\n",
    "        \"KS_extra_total\": int(KS_extra_total)\n",
    "    }\n",
    "\n",
    "\n",
    "    dic_rational_record = {\n",
    "        \"BOOL_RATIONAL_S\": True,\n",
    "        \"BOOL_RATIONAL_W\": True,\n",
    "        \"BOOL_RATIONAL_L\": True,\n",
    "        \"BOOL_RECORD_NO\": False,\n",
    "        \"BOOL_RECORD_S_ON\": False,\n",
    "        \"BOOL_RECORD_W_ON\": False,\n",
    "        \"BOOL_RECORD_L_ON\": False\n",
    "    }\n",
    "    \n",
    "    BOOL_SENTENCE_UNFINISH = True\n",
    "\n",
    "    # sentence = \"Do you know where the engineering department is?\" #\n",
    "    # sentence = \"aaaaa bbbbb ccccc ddddd eeeee fffff ggggg hhhhh iiiii jjjjj kkkkk lllll mmmmm nnnnn ooooo ppppp qqqqq.\"\n",
    "    # sentence = \"How are you?\"\n",
    "    sentence = sentence.strip()\n",
    "    sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "    sentence = sentence.lower()\n",
    "    # sentence = sentence + '.'\n",
    "    word_list = sentence.split(' ')\n",
    "    current_word = word_list[0]\n",
    "\n",
    "    # entry current word\n",
    "    dic_entry_record, dic_rational_record, next_word, T_temp, KS_temp, BOOL_WORD_SELECTED = Enter_current_word(dic_entry_record, dic_rational_record, word_list, current_word)\n",
    "    T_total += T_temp\n",
    "    KS_total += KS_temp\n",
    "    if next_word == '':\n",
    "        BOOL_SENTENCE_UNFINISH = False\n",
    "        if BOOL_WORD_SELECTED == False:\n",
    "            if BOOL_PRINT:\n",
    "                print(\"Last word typed, remove the space after the final word\")\n",
    "            T_total -= T_key\n",
    "            KS_total -= 1\n",
    "            # Special dic_entry_record\n",
    "            dic_entry_record['T_total'] -= T_key\n",
    "            dic_entry_record['T_key_total'] -= T_key\n",
    "            dic_entry_record['KS_total'] -= 1\n",
    "            dic_entry_record['KS_type_total'] -= 1\n",
    "    # else:\n",
    "    #     current_word = next_word\n",
    "        \n",
    "\n",
    "    while BOOL_SENTENCE_UNFINISH:\n",
    "    # check if the sentence is finished and execute follow up process\n",
    "        dic_entry_record, dic_rational_record, T_temp, KS_temp, current_word, BOOL_SENTENCE_UNFINISH = Check_sentence_finish(dic_entry_record, dic_rational_record, current_word, word_list)\n",
    "        T_total += T_temp\n",
    "        KS_total += KS_temp\n",
    "    \n",
    "    # Check interruption\n",
    "    R_interrupt = dic_entry_record['R_interrupt']\n",
    "    T_event = dic_entry_record['T_event']\n",
    "    if random.random() < R_interrupt:\n",
    "        # T_event = 0 \n",
    "        # T_event = 60*random.random()\n",
    "        T_total += T_interrupt(T_event)\n",
    "        if BOOL_PRINT:\n",
    "            print(f\"Interruption event: {T_event} s. Interruption time {T_interrupt(T_event)}\")\n",
    "        dic_entry_record = Update_dic_entry_record(dic_entry_record, T_event_total_temp=T_event)\n",
    "        T_total_entry_rate = T_total - T_interrupt(T_event) + T_event\n",
    "    else:\n",
    "        T_total_entry_rate = T_total\n",
    "    \n",
    "    if BOOL_PRINT:\n",
    "        print(f\"T_total_entry_rate = {T_total_entry_rate}\")\n",
    "        print(f\"T_total = {T_total}\")\n",
    "    \n",
    "    # Calculate the overall impact of bounded rationality\n",
    "    dic_entry_record['T_net_extra'] = dic_entry_record['T_extra_total'] - dic_entry_record['T_react_saving_total']\n",
    "\n",
    "    if BOOL_PRINT:\n",
    "        print(f\"Time: {T_total}\")\n",
    "        print(f\"Keystroke: {KS_total}\")\n",
    "        print(f\"Extra actions count: {dic_entry_record['KS_extra_total']}\")\n",
    "        print(f\"Extra action time: {dic_entry_record['T_extra_total']}\")\n",
    "        print(f\"Saved time from reactions: {dic_entry_record['T_react_saving_total']}\")\n",
    "        print(f\"Net extra time: {dic_entry_record['T_net_extra']}\")\n",
    "        print(\"^^^^^^^^^^^^^^^^^^^^^^^^^\")\n",
    "\n",
    "    return dic_entry_record, T_total, KS_total, T_total_entry_rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single sentence test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence = \"Do you know where the engineering department is?\"\n",
    "# Only test word entry strategy\n",
    "\n",
    "T_key =  0.26 # 0.26 # 0.6\n",
    "T_react_w = 0.45 # 0.45 # 1.20\n",
    "T_react_s = 1.87 # T_react_w * L_s_ave = 1.20*4.23 = 5.08\n",
    "\n",
    "    \n",
    "L_min_w = 3\n",
    "k_look_w = 2\n",
    "p_max_w = 5\n",
    "\n",
    "# L_min_w_n = 1\n",
    "# k_look_w_n = 1\n",
    "# p_max_w_n = 9\n",
    "\n",
    "L_min_s = 3\n",
    "k_look_s = 1\n",
    "p_max_s = 6\n",
    "\n",
    "P_pred_w_c = 0.712\n",
    "P_pred_w_n = 0.575\n",
    "P_pred_s = 0.438\n",
    "\n",
    "# def P_pred_s(current_word_index, L_s): # the probability of the system have correct sentence predictions\n",
    "#     a=1\n",
    "#     b=L_s\n",
    "#     x=current_word_index\n",
    "#     c=0\n",
    "#     return a*math.log(x+1,b)+c\n",
    "\n",
    "R_rational = 1\n",
    "R_error = 0\n",
    "R_interrupt = 0\n",
    "T_event = 5\n",
    "\n",
    "# R_interrupt = 0.0\n",
    "# T_event = 60*random.random()\n",
    "# def T_interrupt(T_event): # the probability of the system have correct sentence predictions\n",
    "#     a=0.189\n",
    "#     c=1.03\n",
    "#     return a*math.log(T_event)+c\n",
    "\n",
    "BOOL_PRINT = True\n",
    "\n",
    "sentence = \"hello where is engineering building\" # \"hello where is\" hello where is engineering building\n",
    "dic_entry_record = Type_one_sentence(sentence, L_min_w=L_min_w, k_look_w=k_look_w, p_max_w=p_max_w, L_min_s=L_min_s, k_look_s=k_look_s, p_max_s=p_max_s, R_rational=R_rational, R_error=R_error, R_interrupt=R_interrupt, T_event=T_event)\n",
    "print(dic_entry_record)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileHCI'23 Experiment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset\n",
    "Dataset is the same as the one we use for real user data collection to minimize the noice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('raw_data.txt') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "average_sentence_length = 0\n",
    "for line in lines:\n",
    "    line = re.sub(r'[^\\w\\s]', '', line)\n",
    "    word_list = line.split(' ')\n",
    "    average_sentence_length += len(word_list)\n",
    "\n",
    "average_sentence_length = average_sentence_length/len(lines)\n",
    "print(f\"Average sentence length: {average_sentence_length}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Experiment 1: KLM\n",
    "AAC surrogate user VS. Able-bodied surrogate user\n",
    "\n",
    "AAC:\n",
    "1. Word Pred - NER\n",
    "2. Word + Sen Pred - KSR\n",
    "3. Word + Sen Pred - NER\n",
    "4. Word + Sen Pred - NER_STD\n",
    "\n",
    "Able-bodied:\n",
    "1. Word + Sen Pred - NER\n",
    "2. Word + Sen Pred - NER_STD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Load Envelope Analysis Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Run(L_min_w=100.0, k_look_w=0.0, p_max_w=0.0, L_min_s=100.0, k_look_s=0.0, p_max_s=0.0, R_rational=1.0, R_error=0.0, R_interrupt=0.0, T_event=5.0):\n",
    "    with open(f'raw_data.txt') as file:\n",
    "        samples = file.readlines()\n",
    "    # samples = [\"Oh so what did dad have to say to you?\"]\n",
    "    data_dic_list = []\n",
    "\n",
    "    for i, s in enumerate(samples):\n",
    "        # print(f\"In sample {i}/{len(samples)}: {s}\")\n",
    "        sample = s.strip()\n",
    "        sample = re.sub(r'[^\\w\\s]', '', sample)\n",
    "        word_list = sample.split(' ')\n",
    "        dic_entry_record, T_total, KS_total, T_total_entry_rate = Type_one_sentence(sample, L_min_w, k_look_w, p_max_w, L_min_s, k_look_s, p_max_s, R_rational, R_error, R_interrupt, T_event) # Take_average_of_one_sentence_result(1, sample)\n",
    "        data_dic = {\n",
    "            # settings\n",
    "            \"L_min_w\": float(L_min_w),\n",
    "            \"k_look_w\": float(k_look_w),\n",
    "            \"p_max_w\": float(p_max_w),\n",
    "            \"L_min_s\": float(L_min_s),\n",
    "            \"k_look_s\": float(k_look_s),\n",
    "            \"p_max_s\": float(p_max_s),\n",
    "            \"P_pred_w_c\": float(P_pred_w_c),\n",
    "            \"P_pred_w_n\": float(P_pred_w_n),\n",
    "            \"T_key\": float(T_key),\n",
    "            \"T_react_w\": float(T_react_w),\n",
    "            \"T_react_s\": float(T_react_s),\n",
    "            \"R_rational\": float(R_rational), # bounded rationality index\n",
    "            \"R_error\": float(R_error), # human error rate\n",
    "            \"R_interrupt\": float(R_interrupt), # interruption rate\n",
    "            \"T_event\": float(T_event), # interruption time\n",
    "\n",
    "            # results\n",
    "            \"sentence\": sample,\n",
    "            \"sentence_length\": int(len(sample)),\n",
    "            \"sentence_length_in_words\": int(len(word_list)),\n",
    "\n",
    "            \n",
    "            \"N_bounded_l_total\": dic_entry_record['N_bounded_l_total'],\n",
    "            \"N_bounded_w_total\": dic_entry_record['N_bounded_w_total'], \n",
    "            \"N_bounded_s_total\": dic_entry_record['N_bounded_s_total'], \n",
    "            \"N_bounded_total\": dic_entry_record['N_bounded_total'],\n",
    "\n",
    "\n",
    "            # T: \n",
    "            \"T_total\": dic_entry_record['T_total'],\n",
    "            \"T_key_total\": dic_entry_record['T_key_total'],\n",
    "            \"T_react_w_total\": dic_entry_record['T_react_w_total'],\n",
    "            \"T_react_s_total\": dic_entry_record['T_react_s_total'],\n",
    "            \"T_react_total\": dic_entry_record['T_react_total'],\n",
    "            # bounded rationality\n",
    "            \"T_extra_total\": dic_entry_record['T_extra_total'],\n",
    "            \"T_extra_s\": dic_entry_record['T_extra_s'],\n",
    "            \"T_extra_w\": dic_entry_record['T_extra_w'],\n",
    "            \"T_extra_l\": dic_entry_record['T_extra_l'],\n",
    "            \"T_net_extra\": dic_entry_record['T_net_extra'],\n",
    "            # human error\n",
    "            \"T_error_total\": dic_entry_record['T_error_total'],       \n",
    "            # interruption\n",
    "            \"T_interrupt_total\": dic_entry_record['T_interrupt_total'],\n",
    "            \"T_event_total\": dic_entry_record['T_event_total'],\n",
    "\n",
    "            # KS: \n",
    "            \"KS_total\": dic_entry_record['KS_total'],\n",
    "            \"KS_type_total\": dic_entry_record['KS_type_total'],\n",
    "            \"KS_select_total\": dic_entry_record['KS_select_total'],\n",
    "            # bounded rationality\n",
    "            \"KS_extra_total\": dic_entry_record['KS_extra_total'],\n",
    "            \"KS_extra_s\": dic_entry_record['KS_extra_s'],\n",
    "            \"KS_extra_w\": dic_entry_record['KS_extra_w'],\n",
    "            \"KS_extra_l\": dic_entry_record['KS_extra_l'],\n",
    "            # human error\n",
    "            \"KS_error_total\": dic_entry_record['KS_error_total'],\n",
    "            # interruption no KS\n",
    "\n",
    "            # basic statistics\n",
    "            \"entry_rate\": float(len(sample)/T_total_entry_rate)*12.0, # wpm\n",
    "            \"net_entry_rate\": float((len(sample)/T_total)*12.0 - (12.0/T_key)), # wpm\n",
    "            \"KS_saving\": float(float(len(sample)) - KS_total),\n",
    "            \"KS_saving_rate\": float(float(len(sample)) - KS_total)/float(len(sample)), # %\n",
    "\n",
    "            # Human performance analyses\n",
    "            \"effective_typing_rate_index\": float(  ((dic_entry_record['KS_total']-dic_entry_record['KS_error_total'])/dic_entry_record['T_key_total']) * T_key ),\n",
    "            \"error_index\": float(dic_entry_record['KS_error_total']/(dic_entry_record['KS_total']-dic_entry_record['KS_extra_total'])),\n",
    "            \"rational_index\": float(1- ( dic_entry_record['KS_extra_total']/(dic_entry_record['KS_total']-dic_entry_record['KS_error_total']) ) ),\n",
    "            \"intuitiveness_index_KS\": float(1- ( (dic_entry_record['KS_error_total']+dic_entry_record['KS_extra_total'])/dic_entry_record['KS_total'] ) ),\n",
    "            \"intuitiveness_index_T\": float(1- ( (dic_entry_record['T_error_total']+dic_entry_record['T_net_extra'])/dic_entry_record['T_total'] ) )\n",
    "\n",
    "        }\n",
    "\n",
    "        data_dic_list.append(data_dic)\n",
    "\n",
    "    # data_dic_list.sort(key=sort_by_sentence_length)\n",
    "\n",
    "    # Collect data\n",
    "    df_data_dic_list = pd.DataFrame(data=data_dic_list)\n",
    "\n",
    "    return df_data_dic_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Set User and System Parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1. Sharable Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_rational = 1\n",
    "R_error = 0\n",
    "R_interrupt = 0\n",
    "\n",
    "T_event = 5\n",
    "\n",
    "def T_interrupt(T_event): # the probability of the system have correct sentence predictions\n",
    "    a=0.189\n",
    "    c=1.03\n",
    "    return a*math.log(T_event)+c\n",
    "\n",
    "# Prediction settings\n",
    "P_pred_w_c = 0.712 # 0.6 # KWickChat\n",
    "P_pred_w_n = 0.575 # 0.5 # KWickChat\n",
    "P_pred_s = 0.438"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2. AAC User Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_key =  0.6 # 0.26 # 0.6\n",
    "T_react_w = 1.20 # 0.45 # 1.20\n",
    "T_react_s = 6.16 # 1.90 # T_react_w * L_s_ave = 1.20*5.13 = 6.16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3. Able-bodied User Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_key =  0.26 # 0.6\n",
    "T_react_w = 0.45 # 1.20\n",
    "T_react_s = 2.31 # T_react_w * L_s_ave = 0.45*5.13 = 2.31"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4. Strategy Parameters: Word Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text entering strategy\n",
    "L_min_w = 2 # 2-10\n",
    "k_look_w = 1 # 0-5\n",
    "p_max_w = 2\n",
    "L_min_s = 100\n",
    "k_look_s = 0\n",
    "p_max_s = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.5. Strategy Parameters: Sen Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text entering strategy\n",
    "L_min_w = 100 \n",
    "k_look_w = 0 \n",
    "p_max_w = 0\n",
    "L_min_s = 2 # 2-10\n",
    "k_look_s = 1 # 0-5 \n",
    "p_max_s = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.6. Strategy Parameters: Word + Sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text entering strategy\n",
    "L_min_w = 4 # 2-10\n",
    "k_look_w = 1 \n",
    "p_max_w = 6\n",
    "L_min_s = 5 # 2-10\n",
    "k_look_s = 1\n",
    "p_max_s = 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. AAC Users"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1. Word Pred Only"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.1.1. L vs k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AAC_Word_L_k():\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(2,10.1,0.1):\n",
    "        for j in np.arange(0,5.1,0.1):\n",
    "            data_frame = Run(L_min_w=i, k_look_w=j, p_max_w=p_max_w, L_min_s=L_min_s, k_look_s=k_look_s, p_max_s=p_max_s, R_rational=R_rational, R_error=R_error, R_interrupt=R_interrupt, T_event=T_event)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'231_AAC_Word_L_k.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOL_PRINT = False\n",
    "aac_word_L_k_results = AAC_Word_L_k()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "readname = f'231_AAC_Word_L_k.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "aac_word_L_k_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and k_look_w\n",
    "aac_word_L_k_data = aac_word_L_k_csv[['net_entry_rate', 'L_min_w', 'k_look_w']]\n",
    "vis_net_entry_rate_mean = aac_word_L_k_data.groupby(['L_min_w', 'k_look_w']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "# vis_net_entry_rate_std = con_ab_net_entry_rate_L_min_w_k_look_w.groupby(['L_min_w', 'k_look_w']).std()\n",
    "# vis_net_entry_rate_std = vis_net_entry_rate_std.reset_index()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('k_look_w', 'L_min_w', 'net_entry_rate')\n",
    "# pivot_table_std = vis_net_entry_rate_std.pivot('k_look_w', 'L_min_w', 'net_entry_rate')\n",
    "# print(pivot_table.shape)\n",
    "# print(pivot_table_std.shape)\n",
    "\n",
    "\n",
    "plt.xlabel('L_min_w', size=25)\n",
    "plt.ylabel('k_look_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "# cbar.set_ticks(np.arange(pivot_table.values.min,pivot_table.values.max,8))\n",
    "# cbar.set_ticks(np.arange(0,5,8))\n",
    "# cbar.set_ticklabels(np.linspace(0,5,8, dtype=np.float64))\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(0, 5, 6, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'231_AAC_Word_L_k.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.1.2. L vs p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text entering strategy\n",
    "L_min_w = 2 # 2-10\n",
    "k_look_w = 1 # 0-5\n",
    "p_max_w = 2 # 2-10\n",
    "L_min_s = 100\n",
    "k_look_s = 0\n",
    "p_max_s = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AAC_Word_L_p():\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(2,10.1,0.1):\n",
    "        for j in np.arange(2,10.1,0.1):\n",
    "            data_frame = Run(L_min_w=i, k_look_w=k_look_w, p_max_w=j, L_min_s=L_min_s, k_look_s=k_look_s, p_max_s=p_max_s, R_rational=R_rational, R_error=R_error, R_interrupt=R_interrupt, T_event=T_event)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'2312_AAC_Word_L_p.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOL_PRINT = False\n",
    "aac_word_L_p_results = AAC_Word_L_p()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "readname = f'2312_AAC_Word_L_p.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "aac_word_L_p_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and p_max_w\n",
    "aac_word_L_p_data = aac_word_L_p_csv[['net_entry_rate', 'L_min_w', 'p_max_w']]\n",
    "vis_net_entry_rate_mean = aac_word_L_p_data.groupby(['L_min_w', 'p_max_w']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "# vis_net_entry_rate_std = con_ab_net_entry_rate_L_min_w_k_look_w.groupby(['L_min_w', 'k_look_w']).std()\n",
    "# vis_net_entry_rate_std = vis_net_entry_rate_std.reset_index()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('p_max_w', 'L_min_w', 'net_entry_rate')\n",
    "# pivot_table_std = vis_net_entry_rate_std.pivot('k_look_w', 'L_min_w', 'net_entry_rate')\n",
    "# print(pivot_table.shape)\n",
    "# print(pivot_table_std.shape)\n",
    "\n",
    "\n",
    "plt.xlabel('L_min_w', size=25)\n",
    "plt.ylabel('p_max_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "# cbar.set_ticks(np.arange(pivot_table.values.min,pivot_table.values.max,8))\n",
    "# cbar.set_ticks(np.arange(0,5,8))\n",
    "# cbar.set_ticklabels(np.linspace(0,5,8, dtype=np.float64))\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'2312_AAC_Word_L_p.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.1.3. p vs k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text entering strategy\n",
    "L_min_w = 4 # 2-10\n",
    "k_look_w = 1 # 0-5\n",
    "p_max_w = 2 # 2-10\n",
    "L_min_s = 100\n",
    "k_look_s = 0\n",
    "p_max_s = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AAC_Word_p_k():\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(2,10.1,0.1):\n",
    "        for j in np.arange(0,5.1,0.1):\n",
    "            data_frame = Run(L_min_w=L_min_w, k_look_w=j, p_max_w=i, L_min_s=L_min_s, k_look_s=k_look_s, p_max_s=p_max_s, R_rational=R_rational, R_error=R_error, R_interrupt=R_interrupt, T_event=T_event)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'2313_AAC_Word_p_k.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOL_PRINT = False\n",
    "aac_word_p_k_results = AAC_Word_p_k()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "readname = f'2313_AAC_Word_p_k.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "aac_word_p_k_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate p_max_w and k_look_w\n",
    "aac_word_p_k_data = aac_word_p_k_csv[['net_entry_rate', 'p_max_w', 'k_look_w']]\n",
    "vis_net_entry_rate_mean = aac_word_p_k_data.groupby(['p_max_w', 'k_look_w']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "# vis_net_entry_rate_std = con_ab_net_entry_rate_L_min_w_k_look_w.groupby(['L_min_w', 'k_look_w']).std()\n",
    "# vis_net_entry_rate_std = vis_net_entry_rate_std.reset_index()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('k_look_w', 'p_max_w', 'net_entry_rate')\n",
    "# pivot_table_std = vis_net_entry_rate_std.pivot('k_look_w', 'L_min_w', 'net_entry_rate')\n",
    "# print(pivot_table.shape)\n",
    "# print(pivot_table_std.shape)\n",
    "\n",
    "\n",
    "plt.xlabel('p_max_w', size=25)\n",
    "plt.ylabel('k_look_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "# cbar.set_ticks(np.arange(pivot_table.values.min,pivot_table.values.max,8))\n",
    "# cbar.set_ticks(np.arange(0,5,8))\n",
    "# cbar.set_ticklabels(np.linspace(0,5,8, dtype=np.float64))\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(0, 5, 6, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'2313_AAC_Word_p_k.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2. Word + Sen Pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text entering strategy\n",
    "L_min_w = 4 # 2-10\n",
    "k_look_w = 0 \n",
    "p_max_w = 2\n",
    "L_min_s = 5 # 2-10\n",
    "k_look_s = 0\n",
    "p_max_s = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AAC_Word_Sen_L_L():\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(2,10.1,0.1):\n",
    "        for j in np.arange(2,10.1,0.1):\n",
    "            data_frame = Run(L_min_w=i, k_look_w=k_look_w, p_max_w=p_max_w, L_min_s=j, k_look_s=k_look_s, p_max_s=p_max_s)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'232_AAC_Word_Sen_L_L.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOL_PRINT = False\n",
    "aac_word_sen_L_L_results = AAC_Word_Sen_L_L()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "readname = f'232_AAC_Word_Sen_L_L.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "aac_word_sen_L_L_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to NER\n",
    "aac_word_sen_L_L_data = aac_word_sen_L_L_csv[['net_entry_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = aac_word_sen_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'net_entry_rate')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'232_AAC_Word_Sen_L_L_NER.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to NER\n",
    "aac_word_sen_L_L_data = aac_word_sen_L_L_csv[['net_entry_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_std = aac_word_sen_L_L_data.groupby(['L_min_w', 'L_min_s']).std()\n",
    "vis_net_entry_rate_std = vis_net_entry_rate_std.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_std.pivot('L_min_w', 'L_min_s', 'net_entry_rate')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=22)\n",
    "print(pivot_table.values.max)\n",
    "\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'232_AAC_Word_Sen_L_L_NER_STD.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to KSR\n",
    "aac_word_sen_L_L_data = aac_word_sen_L_L_csv[['KS_saving_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = aac_word_sen_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'KS_saving_rate')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "# print(pivot_table.values.max)\n",
    "cbar.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cbar.get_ticks()])\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'232_AAC_Word_Sen_L_L_KSR.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3. Sen Pred Only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text entering strategy\n",
    "L_min_w = 100 \n",
    "k_look_w = 0 \n",
    "p_max_w = 0\n",
    "L_min_s = 2 # 2-10\n",
    "k_look_s = 1 # 0-5 \n",
    "p_max_s = 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.3.1. L vs k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AAC_Sen_L_k():\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(2,10.1,0.1):\n",
    "        for j in np.arange(0,5.1,0.1):\n",
    "            data_frame = Run(L_min_w=L_min_w, k_look_w=k_look_w, p_max_w=p_max_w, L_min_s=i, k_look_s=j, p_max_s=p_max_s, R_rational=R_rational, R_error=R_error, R_interrupt=R_interrupt, T_event=T_event)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'2331_AAC_Sen_L_k.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOL_PRINT = False\n",
    "aac_sen_L_k_results = AAC_Sen_L_k()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "readname = f'2331_AAC_Sen_L_k.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "aac_sen_L_k_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and k_look_w\n",
    "aac_sen_L_k_data = aac_sen_L_k_csv[['net_entry_rate', 'L_min_s', 'k_look_s']]\n",
    "vis_net_entry_rate_mean = aac_sen_L_k_data.groupby(['L_min_s', 'k_look_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "# vis_net_entry_rate_std = con_ab_net_entry_rate_L_min_w_k_look_w.groupby(['L_min_w', 'k_look_w']).std()\n",
    "# vis_net_entry_rate_std = vis_net_entry_rate_std.reset_index()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('k_look_s', 'L_min_s', 'net_entry_rate')\n",
    "# pivot_table_std = vis_net_entry_rate_std.pivot('k_look_w', 'L_min_w', 'net_entry_rate')\n",
    "# print(pivot_table.shape)\n",
    "# print(pivot_table_std.shape)\n",
    "\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('k_look_s', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "# cbar.set_ticks(np.arange(pivot_table.values.min,pivot_table.values.max,8))\n",
    "# cbar.set_ticks(np.arange(0,5,8))\n",
    "# cbar.set_ticklabels(np.linspace(0,5,8, dtype=np.float64))\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(0, 5, 6, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'2331_AAC_Sen_L_k.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.3.2. L vs p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AAC_Sen_L_p():\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(2,10.1,0.1):\n",
    "        for j in np.arange(2,10.1,0.1):\n",
    "            data_frame = Run(L_min_w=L_min_w, k_look_w=k_look_w, p_max_w=p_max_w, L_min_s=i, k_look_s=k_look_s, p_max_s=j, R_rational=R_rational, R_error=R_error, R_interrupt=R_interrupt, T_event=T_event)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'2332_AAC_Sen_L_p.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOL_PRINT = False\n",
    "aac_sen_L_p_results = AAC_Sen_L_p()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "readname = f'2332_AAC_Sen_L_p.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "aac_sen_L_p_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and p_max_w\n",
    "aac_sen_L_p_data = aac_sen_L_p_csv[['net_entry_rate', 'L_min_s', 'p_max_s']]\n",
    "vis_net_entry_rate_mean = aac_sen_L_p_data.groupby(['L_min_s', 'p_max_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "# vis_net_entry_rate_std = con_ab_net_entry_rate_L_min_w_k_look_w.groupby(['L_min_w', 'k_look_w']).std()\n",
    "# vis_net_entry_rate_std = vis_net_entry_rate_std.reset_index()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('p_max_s', 'L_min_s', 'net_entry_rate')\n",
    "# pivot_table_std = vis_net_entry_rate_std.pivot('k_look_w', 'L_min_w', 'net_entry_rate')\n",
    "# print(pivot_table.shape)\n",
    "# print(pivot_table_std.shape)\n",
    "\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('p_max_s', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "# cbar.set_ticks(np.arange(pivot_table.values.min,pivot_table.values.max,8))\n",
    "# cbar.set_ticks(np.arange(0,5,8))\n",
    "# cbar.set_ticklabels(np.linspace(0,5,8, dtype=np.float64))\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'2332_AAC_Sen_L_p.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.3.3. p vs k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text entering strategy\n",
    "L_min_w = 100 \n",
    "k_look_w = 0 \n",
    "p_max_w = 0\n",
    "L_min_s = 5 \n",
    "k_look_s = 1 # 0-5\n",
    "p_max_s = 6 # 2-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AAC_Sen_p_k():\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(2,10.1,0.1):\n",
    "        for j in np.arange(0,5.1,0.1):\n",
    "            data_frame = Run(L_min_w=L_min_w, k_look_w=k_look_w, p_max_w=p_max_w, L_min_s=L_min_s, k_look_s=j, p_max_s=i, R_rational=R_rational, R_error=R_error, R_interrupt=R_interrupt, T_event=T_event)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'2333_AAC_Sen_p_k.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOL_PRINT = False\n",
    "aac_sen_p_k_results = AAC_Sen_p_k()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "readname = f'2333_AAC_Sen_p_k.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "aac_sen_p_k_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate p_max_w and k_look_w\n",
    "aac_sen_p_k_data = aac_sen_p_k_csv[['net_entry_rate', 'p_max_s', 'k_look_s']]\n",
    "vis_net_entry_rate_mean = aac_sen_p_k_data.groupby(['p_max_s', 'k_look_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "# vis_net_entry_rate_std = con_ab_net_entry_rate_L_min_w_k_look_w.groupby(['L_min_w', 'k_look_w']).std()\n",
    "# vis_net_entry_rate_std = vis_net_entry_rate_std.reset_index()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('k_look_s', 'p_max_s', 'net_entry_rate')\n",
    "# pivot_table_std = vis_net_entry_rate_std.pivot('k_look_w', 'L_min_w', 'net_entry_rate')\n",
    "# print(pivot_table.shape)\n",
    "# print(pivot_table_std.shape)\n",
    "\n",
    "\n",
    "plt.xlabel('p_max_s', size=25)\n",
    "plt.ylabel('k_look_s', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "# cbar.set_ticks(np.arange(pivot_table.values.min,pivot_table.values.max,8))\n",
    "# cbar.set_ticks(np.arange(0,5,8))\n",
    "# cbar.set_ticklabels(np.linspace(0,5,8, dtype=np.float64))\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(0, 5, 6, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'2333_AAC_Sen_p_k.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Able-bodied Users"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1. Word + Sen Pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def able_Word_Sen_L_L():\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(2,10.1,0.1):\n",
    "        for j in np.arange(2,10.1,0.1):\n",
    "            data_frame = Run(L_min_w=i, k_look_w=k_look_w, p_max_w=p_max_w, L_min_s=j, k_look_s=k_look_s, p_max_s=p_max_s)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'241_able_Word_Sen_L_L.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOL_PRINT = False\n",
    "able_word_sen_L_L_results = able_Word_Sen_L_L()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "readname = f'241_able_Word_Sen_L_L.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "able_word_sen_L_L_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to NER\n",
    "able_word_sen_L_L_data = able_word_sen_L_L_csv[['net_entry_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = able_word_sen_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'net_entry_rate')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'241_able_Word_Sen_L_L_NER.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to NER_STD\n",
    "able_word_sen_L_L_data = able_word_sen_L_L_csv[['net_entry_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_std = able_word_sen_L_L_data.groupby(['L_min_w', 'L_min_s']).std()\n",
    "vis_net_entry_rate_std = vis_net_entry_rate_std.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_std.pivot('L_min_w', 'L_min_s', 'net_entry_rate')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=22)\n",
    "print(pivot_table.values.max)\n",
    "\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'241_able_Word_Sen_L_L_NER_STD.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to KSR\n",
    "aac_word_sen_L_L_data = aac_word_sen_L_L_csv[['KS_saving_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = aac_word_sen_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'KS_saving_rate')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "# print(pivot_table.values.max)\n",
    "cbar.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cbar.get_ticks()])\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'232_AAC_Word_Sen_L_L_KSR.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experiment 2: Human Factors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. User and System Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction settings\n",
    "P_pred_w_c = 0.712 # 0.6 # KWickChat\n",
    "P_pred_w_n = 0.575 # 0.5 # KWickChat\n",
    "P_pred_s = 0.438\n",
    "\n",
    "# AAC user\n",
    "T_key =  0.6 # 0.26 # 0.6\n",
    "T_react_w = 1.20 # 0.45 # 1.20\n",
    "T_react_s = 6.16 # 1.90 # T_react_w * L_s_ave = 1.20*5.13 = 6.16\n",
    "\n",
    "# Text entering strategy\n",
    "L_min_w = 3 # 2-10\n",
    "k_look_w = 0 \n",
    "p_max_w = 2\n",
    "L_min_s = 5 # 2-10\n",
    "k_look_s = 0\n",
    "p_max_s = 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Bounded Rationality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_rational = 1\n",
    "R_error = 0\n",
    "R_interrupt = 0\n",
    "\n",
    "T_event = 5\n",
    "\n",
    "def T_interrupt(T_event): # the probability of the system have correct sentence predictions\n",
    "    a=0.189\n",
    "    c=1.03\n",
    "    return a*math.log(T_event)+c"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1. AAC, Word + Sen Pred, Irrational\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AAC_Word_Sen_B_L_L():\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(2,10.1,0.1):\n",
    "        for j in np.arange(2,10.1,0.1):\n",
    "            data_frame = Run(L_min_w=i, k_look_w=k_look_w, p_max_w=p_max_w, L_min_s=j, k_look_s=k_look_s, p_max_s=p_max_s, R_rational=R_rational, R_error=R_error, R_interrupt=R_interrupt, T_event=T_event)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'321_aac_Word_Sen_B_L_L.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_rational = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOL_PRINT = False\n",
    "aac_word_sen_b_L_L_results = AAC_Word_Sen_B_L_L()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "readname = f'321_aac_Word_Sen_B_L_L.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "aac_word_sen_b_L_L_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to NER\n",
    "aac_word_sen_b_L_L_data = aac_word_sen_b_L_L_csv[['net_entry_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = aac_word_sen_b_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'net_entry_rate')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'321_aac_Word_Sen_B_L_L_NER.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to NER_STD\n",
    "aac_word_sen_b_L_L_data = aac_word_sen_b_L_L_csv[['KS_extra_total', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = aac_word_sen_b_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'KS_extra_total')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'321_aac_Word_Sen_B_L_L_KS_extra.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to KSR\n",
    "aac_word_sen_b_L_L_data = aac_word_sen_b_L_L_csv[['KS_saving_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_KS_saving_rate_mean = aac_word_sen_b_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_KS_saving_rate_mean = vis_KS_saving_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_KS_saving_rate_mean.pivot('L_min_w', 'L_min_s', 'KS_saving_rate')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "# print(pivot_table.values.max)\n",
    "cbar.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cbar.get_ticks()])\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'321_AAC_Word_Sen_b_L_L_KSR.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Human Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_rational = 1\n",
    "R_error = 0\n",
    "R_interrupt = 0\n",
    "\n",
    "T_event = 5\n",
    "\n",
    "def T_interrupt(T_event): # the probability of the system have correct sentence predictions\n",
    "    a=0.189\n",
    "    c=1.03\n",
    "    return a*math.log(T_event)+c"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1. AAC, Word + Sen Pred, Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AAC_Word_Sen_E_L_L():\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(2,10.1,0.1):\n",
    "        for j in np.arange(2,10.1,0.1):\n",
    "            data_frame = Run(L_min_w=i, k_look_w=k_look_w, p_max_w=p_max_w, L_min_s=j, k_look_s=k_look_s, p_max_s=p_max_s, R_rational=1.0, R_error=R_error, R_interrupt=0.0, T_event=5.0)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'331_aac_Word_Sen_E_L_L.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_error = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOL_PRINT = False\n",
    "aac_word_sen_e_L_L_results = AAC_Word_Sen_E_L_L()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "readname = f'331_aac_Word_Sen_E_L_L.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "aac_word_sen_e_L_L_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to NER\n",
    "aac_word_sen_e_L_L_data = aac_word_sen_e_L_L_csv[['net_entry_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = aac_word_sen_e_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'net_entry_rate')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'321_aac_Word_Sen_E_L_L_NER.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to KSR\n",
    "aac_word_sen_e_L_L_data = aac_word_sen_e_L_L_csv[['KS_error_total', 'L_min_w', 'L_min_s']]\n",
    "vis_KS_saving_rate_mean = aac_word_sen_e_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_KS_saving_rate_mean = vis_KS_saving_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_KS_saving_rate_mean.pivot('L_min_w', 'L_min_s', 'KS_error_total')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "# print(pivot_table.values.max)\n",
    "# cbar.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cbar.get_ticks()])\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'331_AAC_Word_Sen_e_L_L_KSR.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Interruption"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1. AAC, Word + Sen Pred, Interruption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AAC_Word_Sen_I_L_L():\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(2,10.1,0.1):\n",
    "        for j in np.arange(2,10.1,0.1):\n",
    "            data_frame = Run(L_min_w=i, k_look_w=k_look_w, p_max_w=p_max_w, L_min_s=j, k_look_s=k_look_s, p_max_s=p_max_s, R_rational=1.0, R_error=0.0, R_interrupt=R_interrupt, T_event=T_event)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'341_aac_Word_Sen_I_L_L.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_interrupt = 0.1\n",
    "T_event = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_interrupt = 0.1\n",
    "T_event = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_interrupt = 0.5\n",
    "T_event = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_interrupt = 0.5\n",
    "T_event = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOL_PRINT = False\n",
    "aac_word_sen_i_L_L_results = AAC_Word_Sen_I_L_L()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "readname = f'341_aac_Word_Sen_I_L_L.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "aac_word_sen_i_L_L_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to NER\n",
    "aac_word_sen_i_L_L_data = aac_word_sen_i_L_L_csv[['net_entry_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = aac_word_sen_i_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'net_entry_rate')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'341_aac_Word_Sen_I_L_L_NER.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. KLM-BEI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.1. AAC, Word + Sen Pred, BEI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AAC_Word_Sen_BEI_B_E():\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(0,1.05,0.05):\n",
    "        for j in np.arange(0,1.05,0.05):\n",
    "            data_frame = Run(L_min_w=L_min_w, k_look_w=k_look_w, p_max_w=p_max_w, L_min_s=L_min_s, k_look_s=k_look_s, p_max_s=p_max_s, R_rational=i, R_error=j, R_interrupt=0.0, T_event=5.0)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'351_aac_Word_Sen_BEI_B_E.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text entering strategy\n",
    "L_min_w = 4 \n",
    "k_look_w = 0\n",
    "p_max_w = 2\n",
    "L_min_s = 5 \n",
    "k_look_s = 0\n",
    "p_max_s = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_interrupt = 0.5\n",
    "\n",
    "T_event = 5\n",
    "\n",
    "def T_interrupt(T_event): # the probability of the system have correct sentence predictions\n",
    "    a=0.189\n",
    "    c=1.03\n",
    "    return a*math.log(T_event)+c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOL_PRINT = False\n",
    "aac_word_sen_BEI_B_E_results = AAC_Word_Sen_BEI_B_E()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "readname = f'351_aac_Word_Sen_BEI_B_E.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "aac_word_sen_bei_B_E_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate R_rational and R_error to NER\n",
    "aac_word_sen_bei_B_E_data = aac_word_sen_bei_B_E_csv[['net_entry_rate', 'R_rational', 'R_error']]\n",
    "vis_net_entry_rate_mean = aac_word_sen_bei_B_E_data.groupby(['R_rational', 'R_error']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('R_rational', 'R_error', 'net_entry_rate')\n",
    "\n",
    "plt.xlabel('R_error (%)', size=25)\n",
    "plt.ylabel('R_rational (%)', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,5))\n",
    "xticks = np.linspace(0, 100, 5, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,5))\n",
    "yticks = np.linspace(0, 100, 5, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'351_aac_Word_Sen_BEI_B_E_NER.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate R_rational and R_error to KSR\n",
    "aac_word_sen_bei_B_E_data = aac_word_sen_bei_B_E_csv[['KS_saving_rate', 'R_rational', 'R_error']]\n",
    "vis_net_entry_rate_mean = aac_word_sen_bei_B_E_data.groupby(['R_rational', 'R_error']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('R_rational', 'R_error', 'KS_saving_rate')\n",
    "\n",
    "plt.xlabel('R_error (%)', size=25)\n",
    "plt.ylabel('R_rational (%)', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "cbar.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cbar.get_ticks()])\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,5))\n",
    "xticks = np.linspace(0, 100, 5, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,5))\n",
    "yticks = np.linspace(0, 100, 5, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'351_aac_Word_Sen_BEI_B_E_KSR.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.2. AAC, BEI, NER, KSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AAC user \n",
    "T_key =  0.6 \n",
    "T_react_w = 1.2 \n",
    "T_react_s = 6.16 \n",
    "\n",
    "R_rational = 0.8\n",
    "R_error = 0.1\n",
    "R_interrupt = 0.2\n",
    "T_event = 5\n",
    "\n",
    "# Prediction settings\n",
    "P_pred_w_c = 0.712 # empirical data\n",
    "P_pred_w_n = 0.575 # empirical data\n",
    "P_pred_s = 0.438\n",
    "\n",
    "# Text entering strategy\n",
    "L_min_w = 4 # 2-10\n",
    "k_look_w = 1\n",
    "p_max_w = 6\n",
    "L_min_s = 5 # 2-10\n",
    "k_look_s = 1\n",
    "p_max_s = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AAC_Word_Sen_BEI_L_L():\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(2,10.1,0.1):\n",
    "        for j in np.arange(2,10.1,0.1):\n",
    "            data_frame = Run(L_min_w=i, k_look_w=k_look_w, p_max_w=p_max_w, L_min_s=j, k_look_s=k_look_s, p_max_s=p_max_s, R_rational=R_rational, R_error=R_error, R_interrupt=R_interrupt, T_event=T_event)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'352_aac_Word_Sen_BEI_L_L.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOL_PRINT = False\n",
    "aac_word_sen_bei_L_L_results = AAC_Word_Sen_BEI_L_L()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "readname = f'352_aac_Word_Sen_BEI_L_L.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "aac_word_sen_bei_L_L_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to NER\n",
    "aac_word_sen_bei_L_L_data = aac_word_sen_bei_L_L_csv[['net_entry_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = aac_word_sen_bei_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'net_entry_rate')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'352_aac_Word_Sen_BEI_L_L_NER.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to NER\n",
    "aac_word_sen_bei_L_L_data = aac_word_sen_bei_L_L_csv[['net_entry_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_std = aac_word_sen_bei_L_L_data.groupby(['L_min_w', 'L_min_s']).std()\n",
    "vis_net_entry_rate_std = vis_net_entry_rate_std.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_std.pivot('L_min_w', 'L_min_s', 'net_entry_rate')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'352_aac_Word_Sen_BEI_L_L_NER.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to KSR\n",
    "aac_word_sen_bei_L_L_data = aac_word_sen_bei_L_L_csv[['KS_saving_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_ks_saving_rate_mean = aac_word_sen_bei_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_ks_saving_rate_mean = vis_ks_saving_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_ks_saving_rate_mean.pivot('L_min_w', 'L_min_s', 'KS_saving_rate')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "cbar.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cbar.get_ticks()])\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'352_aac_Word_Sen_BEI_L_L_KSR.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to KSR_STD\n",
    "aac_word_sen_bei_L_L_data = aac_word_sen_bei_L_L_csv[['KS_saving_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_ks_saving_rate_mean = aac_word_sen_bei_L_L_data.groupby(['L_min_w', 'L_min_s']).std()\n",
    "vis_ks_saving_rate_mean = vis_ks_saving_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_ks_saving_rate_mean.pivot('L_min_w', 'L_min_s', 'KS_saving_rate')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "# cbar.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cbar.get_ticks()])\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'352_aac_Word_Sen_BEI_L_L_KSR_STD.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to RI\n",
    "aac_word_sen_bei_L_L_data = aac_word_sen_bei_L_L_csv[['rational_index', 'L_min_w', 'L_min_s']]\n",
    "vis_ks_saving_rate_mean = aac_word_sen_bei_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_ks_saving_rate_mean = vis_ks_saving_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_ks_saving_rate_mean.pivot('L_min_w', 'L_min_s', 'rational_index')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "cbar.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cbar.get_ticks()])\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'352_aac_Word_Sen_BEI_L_L_RI.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to EI\n",
    "aac_word_sen_bei_L_L_data = aac_word_sen_bei_L_L_csv[['error_index', 'L_min_w', 'L_min_s']]\n",
    "vis_ks_saving_rate_mean = aac_word_sen_bei_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_ks_saving_rate_mean = vis_ks_saving_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_ks_saving_rate_mean.pivot('L_min_w', 'L_min_s', 'error_index')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "cbar.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cbar.get_ticks()])\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'352_aac_Word_Sen_BEI_L_L_EI.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to UFI_KS\n",
    "aac_word_sen_bei_L_L_data = aac_word_sen_bei_L_L_csv[['intuitiveness_index_KS', 'L_min_w', 'L_min_s']]\n",
    "vis_ks_saving_rate_mean = aac_word_sen_bei_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_ks_saving_rate_mean = vis_ks_saving_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_ks_saving_rate_mean.pivot('L_min_w', 'L_min_s', 'intuitiveness_index_KS')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "cbar.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cbar.get_ticks()])\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'352_aac_Word_Sen_BEI_L_L_UFI_KS.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to UFI_T\n",
    "aac_word_sen_bei_L_L_data = aac_word_sen_bei_L_L_csv[['intuitiveness_index_T', 'L_min_w', 'L_min_s']]\n",
    "vis_ks_saving_rate_mean = aac_word_sen_bei_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_ks_saving_rate_mean = vis_ks_saving_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_ks_saving_rate_mean.pivot('L_min_w', 'L_min_s', 'intuitiveness_index_T')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "cbar.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cbar.get_ticks()])\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'352_aac_Word_Sen_BEI_L_L_UFI_T.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experiment 3: Apply real user parameter back to model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Participant 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real user P1\n",
    "T_key =  0.25 \n",
    "T_react_w = 0.75 \n",
    "T_react_s = 2.18 \n",
    "\n",
    "# Prediction settings\n",
    "P_pred_w_c = 0.712 # empirical data\n",
    "P_pred_w_n = 0.575 # empirical data\n",
    "P_pred_s = 0.438\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1. KLM-BEI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_rational = 0.863\n",
    "R_error = 0.091\n",
    "R_interrupt = 1.02\n",
    "\n",
    "T_event = 3.92\n",
    "\n",
    "def T_interrupt(T_event): # the probability of the system have correct sentence predictions\n",
    "    a=0.189\n",
    "    c=1.03\n",
    "    return a*math.log(T_event)+c\n",
    "\n",
    "# Text entering strategy\n",
    "L_min_w = 5 # 2-10\n",
    "k_look_w = 5 \n",
    "p_max_w = 6\n",
    "L_min_s = 3 # 2-10\n",
    "k_look_s = 2\n",
    "p_max_s = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_1_Word_Sen_BEI_L_L():\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(2,10.1,0.1):\n",
    "        for j in np.arange(2,10.1,0.1):\n",
    "            data_frame = Run(L_min_w=i, k_look_w=k_look_w, p_max_w=p_max_w, L_min_s=j, k_look_s=k_look_s, p_max_s=p_max_s, R_rational=R_rational, R_error=R_error, R_interrupt=R_interrupt, T_event=T_event)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'411_real_1_Word_Sen_BEI_L_L.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOL_PRINT = False\n",
    "real_1_word_sen_BEI_L_L_results = real_1_Word_Sen_BEI_L_L()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "readname = f'411_real_1_Word_Sen_BEI_L_L.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "real_1_word_sen_bei_L_L_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to NER\n",
    "real_1_word_sen_bei_L_L_data = real_1_word_sen_bei_L_L_csv[['entry_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = real_1_word_sen_bei_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'entry_rate')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'411_real_1_Word_Sen_BEI_L_L_ER.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to KSR\n",
    "real_1_word_sen_bei_L_L_data = real_1_word_sen_bei_L_L_csv[['KS_saving_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = real_1_word_sen_bei_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'KS_saving_rate')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "cbar.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cbar.get_ticks()])\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'411_real_1_Word_Sen_BEI_L_L_KSR.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to RI\n",
    "real_1_word_sen_bei_L_L_data = real_1_word_sen_bei_L_L_csv[['rational_index', 'L_min_w', 'L_min_s']]\n",
    "vis_rational_index_mean = real_1_word_sen_bei_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_rational_index_mean = vis_rational_index_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_rational_index_mean.pivot('L_min_w', 'L_min_s', 'rational_index')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "cbar.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cbar.get_ticks()])\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'411_real_1_Word_Sen_BEI_L_L_RI.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to RI\n",
    "real_1_word_sen_bei_L_L_data = real_1_word_sen_bei_L_L_csv[['error_index', 'L_min_w', 'L_min_s']]\n",
    "vis_error_index_mean = real_1_word_sen_bei_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_error_index_mean = vis_error_index_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_error_index_mean.pivot('L_min_w', 'L_min_s', 'error_index')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "cbar.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cbar.get_ticks()])\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'411_real_1_Word_Sen_BEI_L_L_EI.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to UFI_KS\n",
    "real_1_word_sen_bei_L_L_data = real_1_word_sen_bei_L_L_csv[['intuitiveness_index_KS', 'L_min_w', 'L_min_s']]\n",
    "vis_intuitiveness_index_ks_mean = real_1_word_sen_bei_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_intuitiveness_index_ks_mean = vis_intuitiveness_index_ks_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_intuitiveness_index_ks_mean.pivot('L_min_w', 'L_min_s', 'intuitiveness_index_KS')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "cbar.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cbar.get_ticks()])\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'411_real_1_Word_Sen_BEI_L_L_UFI_KS.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to UFI_T\n",
    "real_1_word_sen_bei_L_L_data = real_1_word_sen_bei_L_L_csv[['intuitiveness_index_T', 'L_min_w', 'L_min_s']]\n",
    "vis_intuitiveness_index_t_mean = real_1_word_sen_bei_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_intuitiveness_index_t_mean = vis_intuitiveness_index_t_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_intuitiveness_index_t_mean.pivot('L_min_w', 'L_min_s', 'intuitiveness_index_T')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "cbar.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cbar.get_ticks()])\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'411_real_1_Word_Sen_BEI_L_L_UFI_T.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2. KLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real user P1\n",
    "T_key =  0.25 \n",
    "T_react_w = 0.75 \n",
    "T_react_s = 2.18 \n",
    "\n",
    "\n",
    "\n",
    "# Prediction settings\n",
    "P_pred_w_c = 0.712 # empirical data\n",
    "P_pred_w_n = 0.575 # empirical data\n",
    "P_pred_s = 0.438\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KLM\n",
    "R_rational = 1\n",
    "R_error = 0\n",
    "R_interrupt = 0\n",
    "\n",
    "T_event = 0\n",
    "\n",
    "def T_interrupt(T_event): # the probability of the system have correct sentence predictions\n",
    "    a=0.189\n",
    "    c=1.03\n",
    "    return 0\n",
    "\n",
    "# Text entering strategy\n",
    "L_min_w = 5 # 2-10\n",
    "k_look_w = 5 \n",
    "p_max_w = 6\n",
    "L_min_s = 3 # 2-10\n",
    "k_look_s = 2\n",
    "p_max_s = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_1_Word_Sen_KLM_L_L():\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(2,10.1,0.1):\n",
    "        for j in np.arange(2,10.1,0.1):\n",
    "            data_frame = Run(L_min_w=i, k_look_w=k_look_w, p_max_w=p_max_w, L_min_s=j, k_look_s=k_look_s, p_max_s=p_max_s, R_rational=R_rational, R_error=R_error, R_interrupt=R_interrupt, T_event=T_event)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'412_real_1_Word_Sen_KLM_L_L.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOL_PRINT = False\n",
    "real_1_word_sen_KLM_L_L_results = real_1_Word_Sen_KLM_L_L()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "readname = f'412_real_1_Word_Sen_KLM_L_L.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "real_1_word_sen_klm_L_L_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to NER\n",
    "real_1_word_sen_klm_L_L_data = real_1_word_sen_klm_L_L_csv[['entry_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = real_1_word_sen_klm_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'entry_rate')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'412_real_1_Word_Sen_KLM_L_L_NER.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to KSR\n",
    "real_1_word_sen_klm_L_L_data = real_1_word_sen_klm_L_L_csv[['KS_saving_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = real_1_word_sen_klm_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'KS_saving_rate')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "cbar.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cbar.get_ticks()])\n",
    "\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'412_real_1_Word_Sen_KLM_L_L_KSR.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Participant 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real user P2\n",
    "T_key =  0.32 \n",
    "T_react_w = 0.77 \n",
    "T_react_s = 1.18 \n",
    "\n",
    "# Prediction settings\n",
    "P_pred_w_c = 0.712 # empirical data\n",
    "P_pred_w_n = 0.575 # empirical data\n",
    "P_pred_s = 0.438\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1. KLM-BEI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_rational = 0.878\n",
    "R_error = 0.029\n",
    "R_interrupt = 1.07\n",
    "\n",
    "T_event = 3.21\n",
    "\n",
    "def T_interrupt(T_event): # the probability of the system have correct sentence predictions\n",
    "    a=0.189\n",
    "    c=1.03\n",
    "    return a*math.log(T_event)+c\n",
    "\n",
    "# Text entering strategy\n",
    "L_min_w = 4 # 2-10\n",
    "k_look_w = 4 \n",
    "p_max_w = 7\n",
    "L_min_s = 5 # 2-10\n",
    "k_look_s = 4\n",
    "p_max_s = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_2_Word_Sen_BEI_L_L():\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(2,10.1,0.1):\n",
    "        for j in np.arange(2,10.1,0.1):\n",
    "            data_frame = Run(L_min_w=i, k_look_w=k_look_w, p_max_w=p_max_w, L_min_s=j, k_look_s=k_look_s, p_max_s=p_max_s)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'421_real_2_Word_Sen_BEI_L_L.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOL_PRINT = False\n",
    "real_2_word_sen_BEI_L_L_results = real_2_Word_Sen_BEI_L_L()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "readname = f'421_real_2_Word_Sen_BEI_L_L.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "real_2_word_sen_bei_L_L_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to ER\n",
    "real_2_word_sen_bei_L_L_data = real_2_word_sen_bei_L_L_csv[['entry_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = real_2_word_sen_bei_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'entry_rate')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'421_real_2_Word_Sen_BEI_L_L_ER.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to KSR\n",
    "real_2_word_sen_bei_L_L_data = real_2_word_sen_bei_L_L_csv[['KS_saving_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = real_2_word_sen_bei_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'KS_saving_rate')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "cbar.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cbar.get_ticks()])\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'421_real_2_Word_Sen_BEI_L_L_KSR.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2. KLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_rational = 1\n",
    "R_error = 0\n",
    "R_interrupt = 0\n",
    "\n",
    "T_event = 5.41\n",
    "\n",
    "def T_interrupt(T_event): # the probability of the system have correct sentence predictions\n",
    "    a=0.189\n",
    "    c=1.03\n",
    "    return 0\n",
    "\n",
    "# Text entering strategy\n",
    "L_min_w = 4 # 2-10\n",
    "k_look_w = 4 \n",
    "p_max_w = 7\n",
    "L_min_s = 5 # 2-10\n",
    "k_look_s = 4\n",
    "p_max_s = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_2_Word_Sen_KLM_L_L():\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(2,10.1,0.1):\n",
    "        for j in np.arange(2,10.1,0.1):\n",
    "            data_frame = Run(L_min_w=i, k_look_w=k_look_w, p_max_w=p_max_w, L_min_s=j, k_look_s=k_look_s, p_max_s=p_max_s)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'422_real_2_Word_Sen_KLM_L_L.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOL_PRINT = False\n",
    "real_2_word_sen_KLM_L_L_results = real_2_Word_Sen_KLM_L_L()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "readname = f'422_real_2_Word_Sen_KLM_L_L.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "real_2_word_sen_klm_L_L_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to NER\n",
    "real_2_word_sen_klm_L_L_data = real_2_word_sen_klm_L_L_csv[['entry_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = real_2_word_sen_klm_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'entry_rate')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'422_real_2_Word_Sen_KLM_L_L_NER.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to KSR\n",
    "real_2_word_sen_klm_L_L_data = real_2_word_sen_klm_L_L_csv[['KS_saving_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = real_2_word_sen_klm_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'KS_saving_rate')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "cbar.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cbar.get_ticks()])\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'422_real_2_Word_Sen_KLM_L_L_KSR.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Participant 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real user P3\n",
    "T_key =  0.27 \n",
    "T_react_w = 0.98 \n",
    "T_react_s = 0.87 \n",
    "\n",
    "# Prediction settings\n",
    "P_pred_w_c = 0.712 # empirical data\n",
    "P_pred_w_n = 0.575 # empirical data\n",
    "P_pred_s = 0.438\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1. KLM-BEI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_rational = 0.888\n",
    "R_error = 0.060\n",
    "R_interrupt = 0.08\n",
    "\n",
    "T_event = 6.21\n",
    "\n",
    "def T_interrupt(T_event): # the probability of the system have correct sentence predictions\n",
    "    a=0.189\n",
    "    c=1.03\n",
    "    return a*math.log(T_event)+c\n",
    "\n",
    "# Text entering strategy\n",
    "L_min_w = 4 # 2-10\n",
    "k_look_w = 1 \n",
    "p_max_w = 6\n",
    "L_min_s = 5 # 2-10\n",
    "k_look_s = 1\n",
    "p_max_s = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_3_Word_Sen_BEI_L_L():\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(2,10.1,0.1):\n",
    "        for j in np.arange(2,10.1,0.1):\n",
    "            data_frame = Run(L_min_w=i, k_look_w=k_look_w, p_max_w=p_max_w, L_min_s=j, k_look_s=k_look_s, p_max_s=p_max_s)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'431_real_3_Word_Sen_BEI_L_L.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOL_PRINT = False\n",
    "real_3_word_sen_BEI_L_L_results = real_3_Word_Sen_BEI_L_L()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "readname = f'431_real_3_Word_Sen_BEI_L_L.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "real_3_word_sen_bei_L_L_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to NER\n",
    "real_3_word_sen_bei_L_L_data = real_3_word_sen_bei_L_L_csv[['net_entry_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = real_3_word_sen_bei_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'net_entry_rate')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'431_real_3_Word_Sen_BEI_L_L_NER.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to KSR\n",
    "real_3_word_sen_bei_L_L_data = real_3_word_sen_bei_L_L_csv[['KS_saving_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = real_3_word_sen_bei_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'KS_saving_rate')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'431_real_3_Word_Sen_BEI_L_L_KSR.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2. KLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_rational = 1\n",
    "R_error = 0\n",
    "R_interrupt = 0\n",
    "\n",
    "T_event = 5.41\n",
    "\n",
    "def T_interrupt(T_event): # the probability of the system have correct sentence predictions\n",
    "    a=0.189\n",
    "    c=1.03\n",
    "    return 0\n",
    "\n",
    "# Text entering strategy\n",
    "L_min_w = 4 # 2-10\n",
    "k_look_w = 1 \n",
    "p_max_w = 6\n",
    "L_min_s = 5 # 2-10\n",
    "k_look_s = 1\n",
    "p_max_s = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_3_Word_Sen_KLM_L_L():\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(2,10.1,0.1):\n",
    "        for j in np.arange(2,10.1,0.1):\n",
    "            data_frame = Run(L_min_w=i, k_look_w=k_look_w, p_max_w=p_max_w, L_min_s=j, k_look_s=k_look_s, p_max_s=p_max_s)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'432_real_3_Word_Sen_KLM_L_L.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOL_PRINT = False\n",
    "real_3_word_sen_KLM_L_L_results = real_3_Word_Sen_KLM_L_L()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "readname = f'432_real_3_Word_Sen_KLM_L_L.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "real_3_word_sen_klm_L_L_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to NER\n",
    "real_3_word_sen_klm_L_L_data = real_3_word_sen_klm_L_L_csv[['net_entry_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = real_3_word_sen_klm_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'net_entry_rate')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'432_real_3_Word_Sen_KLM_L_L_NER.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s to KSR\n",
    "real_3_word_sen_klm_L_L_data = real_3_word_sen_klm_L_L_csv[['KS_saving_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = real_3_word_sen_klm_L_L_data.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'KS_saving_rate')\n",
    "\n",
    "plt.xlabel('L_min_s', size=25)\n",
    "plt.ylabel('L_min_w', size=25)\n",
    "im = plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "print(pivot_table.values.max)\n",
    "\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'432_real_3_Word_Sen_KLM_L_L_KSR.csv'\n",
    "outdir = './analysis_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load function: Randomly collect samples from daily conversation dataset with AAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def No_duplicate_words(word_list):\n",
    "    word_list_lower = [x.lower() for x in word_list]\n",
    "    if len(set(word_list_lower)) < len(word_list_lower):\n",
    "        return False\n",
    "    return True   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Take_sample_from_original_source(sample_size):\n",
    "    with open('sent_train_aac.txt') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    sentence_samples = []\n",
    "    average_sentence_length = 0\n",
    "    for i in range(sample_size):\n",
    "        sample = int(random.random()*len(lines))\n",
    "        line_temp = lines[sample].strip()\n",
    "        line_temp = re.sub(r'[^\\w\\s]', '', line_temp)\n",
    "        line_temp_list = line_temp.split(' ')\n",
    "        \n",
    "        if No_duplicate_words(line_temp_list):\n",
    "            sentence_samples.append(lines[sample])\n",
    "        else: \n",
    "            BOOL_DUPLICATE = True\n",
    "            if sample < len(lines):\n",
    "                sample_temp = sample + 1\n",
    "            else:\n",
    "                if sample > 10:\n",
    "                    sample_temp = sample - 10\n",
    "                else:\n",
    "                    sample_temp = 10\n",
    "            while BOOL_DUPLICATE:\n",
    "                # print(sample_temp)\n",
    "                line_temp = lines[sample_temp].strip()\n",
    "                line_temp_list = line_temp.split(' ')\n",
    "                if No_duplicate_words(line_temp_list):\n",
    "                    sentence_samples.append(lines[sample_temp])\n",
    "                    BOOL_DUPLICATE = False\n",
    "                    break\n",
    "                else:\n",
    "                    sample_temp += 1\n",
    "                \n",
    "        if BOOL_PRINT:\n",
    "            print(f\"{i+1}. Select sample {sample}: {lines[sample]}\")\n",
    "\n",
    "    with open(f'aac_daily_conversation_sample_{sample_size}.txt', 'w') as file:\n",
    "        for sample in sentence_samples:\n",
    "            word_list = sample.split(' ')\n",
    "            average_sentence_length += len(word_list)\n",
    "            file.write(\"%s\" % sample) \n",
    "\n",
    "    average_sentence_length = average_sentence_length/len(sentence_samples)\n",
    "    print(f\"Average sentence length: {average_sentence_length}\")\n",
    "    return average_sentence_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution: Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 100\n",
    "L_s_ave = Take_sample_from_original_source(SAMPLE_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exam data validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 100\n",
    "\n",
    "# Word prediction settings\n",
    "P_pred_w_c = 0.712\n",
    "P_pred_w_n = 0.575\n",
    "P_pred_s = 0.438\n",
    "\n",
    "# Sentence prediction settings\n",
    "# def P_pred_s(current_word_index, L_s): # the probability of the system have correct sentence predictions\n",
    "#     a=1\n",
    "#     b=L_s\n",
    "#     x=current_word_index\n",
    "#     c=0\n",
    "#     return a*math.log(x+1,b)+c\n",
    "\n",
    "# User profile\n",
    "T_key = 0.26 #2.5\n",
    "T_react_w = 0.45\n",
    "T_react_s = 1.90 # T_react_w * average_sentence_length\n",
    "\n",
    "R_rational = 0.9\n",
    "R_error = 0.1\n",
    "\n",
    "R_interrupt = 0.1\n",
    "T_event = 60*random.random()\n",
    "def T_interrupt(T_event): # the probability of the system have correct sentence predictions\n",
    "    a=0.189\n",
    "    c=1.03\n",
    "    return a*math.log(T_event)+c\n",
    "\n",
    "# Text entering strategy\n",
    "L_min_w = 1\n",
    "k_look_w = 1\n",
    "p_max_w = 4\n",
    "\n",
    "L_min_s = 2\n",
    "k_look_s = 1\n",
    "p_max_s = 6\n",
    "\n",
    "\n",
    "# with open(f'aac_daily_conversation_sample_{SAMPLE_SIZE}.txt') as file:\n",
    "with open(f'raw_data.txt') as file:\n",
    "    samples = file.readlines()\n",
    "# samples = [\"Oh so what did dad have to say to you?\"]\n",
    "data_dic_list = []\n",
    "\n",
    "for i, s in enumerate(samples):\n",
    "    # print(f\"In sample {i}/{len(samples)}: {s}\")\n",
    "    sample = s.strip()\n",
    "    word_list = sample.split(' ')\n",
    "    dic_entry_record, T_total, KS_total = Type_one_sentence(sample, L_min_w, k_look_w, p_max_w, L_min_s, k_look_s, p_max_s) # Take_average_of_one_sentence_result(1, sample)\n",
    "    \n",
    "    data_dic = {\n",
    "        \"L_min_w\": float(L_min_w),\n",
    "        \"k_look_w\": float(k_look_w),\n",
    "        \"p_max_w\": float(p_max_w),\n",
    "        \"L_min_s\": float(L_min_s),\n",
    "        \"k_look_s\": float(k_look_s),\n",
    "        \"p_max_s\": float(p_max_s),\n",
    "        \"P_pred_w_c\": float(P_pred_w_c),\n",
    "        \"P_pred_w_n\": float(P_pred_w_n),\n",
    "        \"T_key\": float(T_key),\n",
    "        \"T_react_w\": float(T_react_w),\n",
    "        \"T_react_s\": float(T_react_s),\n",
    "        \"R_rational\": float(R_rational), # bounded rationality index\n",
    "        \"R_error\": float(R_error), # human error rate\n",
    "        \"R_interrupt\": float(R_interrupt), # interruption rate\n",
    "        \"T_event\": float(T_event), # interruption time\n",
    "        # \"T_interrupt\": \n",
    "        \n",
    "        \"sentence\": sample,\n",
    "        \"sentence_length\": int(len(sample)),\n",
    "        \"sentence_length_in_words\": int(len(word_list)),\n",
    "        \"T_total\": float(T_total),\n",
    "        \"KS_total\": float(KS_total),\n",
    "        \"entry_rate\": float(KS_total/T_total)*12.0, # wpm\n",
    "        # \"effective_entry_rate\":\n",
    "        \"net_entry_rate\": float((KS_total/T_total)*12.0 - (12.0/T_key)), # wpm\n",
    "        # \"net_effective_entry_rate\":\n",
    "        \"KS_saving\": float(float(len(sample)) - KS_total),\n",
    "        \"KS_saving_rate\": float(float(len(sample)) - KS_total)/(float(len(sample)))*100 # %\n",
    "    }\n",
    "    data_dic_list.append(data_dic)\n",
    "df_data_dic_list = pd.DataFrame(data=data_dic_list)\n",
    "df_data_dic_list.to_excel('exam-data-validity.xlsx')\n",
    "\n",
    "net_entry_rate_mean = df_data_dic_list.groupby(['sentence_length_in_words'])['net_entry_rate'].mean()\n",
    "df_data_dic_list.plot.scatter(x='sentence_length' ,y='sentence_length_in_words')\n",
    "print(net_entry_rate_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: KLM - Sentence generation system\n",
    "Run experiment under error-free, interruption-free and rational conditions. Aim to evaluate the efficiency of the system design with different entry strategies for the AAC user. User data from (Koester, 1994)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load fixed parameters for AAC users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User profile\n",
    "T_key =  0.26 # 0.26 # 0.6\n",
    "T_react_w = 0.45 # 0.45 # 1.20\n",
    "T_react_s = 1.90 # 1.90 # T_react_w * L_s_ave = 1.20*4.23 = 5.08\n",
    "\n",
    "R_rational = 1\n",
    "R_error = 0\n",
    "R_interrupt = 0\n",
    "\n",
    "T_event = 5\n",
    "\n",
    "def T_interrupt(T_event): # the probability of the system have correct sentence predictions\n",
    "    a=0.189\n",
    "    c=1.03\n",
    "    return a*math.log(T_event)+c\n",
    "\n",
    "# Word prediction settings\n",
    "P_pred_w_c = 0.712 # 0.6 # KWickChat\n",
    "P_pred_w_n = 0.575 # 0.5 # KWickChat\n",
    "P_pred_s = 0.438\n",
    "\n",
    "# Sentence prediction settings\n",
    "# def P_pred_s(current_word_index, L_s): # the probability of the system have correct sentence predictions\n",
    "#     a=1\n",
    "#     b=L_s\n",
    "#     x=current_word_index\n",
    "#     c=0\n",
    "#     return a*math.log(x+1,b)+c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load initial variables: entry without assistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text entering strategy\n",
    "L_min_w = 100\n",
    "k_look_w = 0\n",
    "p_max_w = 0\n",
    "\n",
    "L_min_s = 100\n",
    "k_look_s = 0\n",
    "p_max_s = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load fundamental function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sort_by_sentence_length(e):\n",
    "#     return e[\"sentence_length_in_words\"]\n",
    "    \n",
    "def Run(SAMPLE_SIZE, CONDITION, L_min_w=100.0, k_look_w=0.0, p_max_w=0.0, L_min_s=100.0, k_look_s=0.0, p_max_s=0.0, R_rational=1.0, R_error=0.0, R_interrupt=0.0, T_event=5.0):\n",
    "    with open(f'aac_daily_conversation_sample_{SAMPLE_SIZE}.txt') as file:\n",
    "        samples = file.readlines()\n",
    "    # samples = [\"Oh so what did dad have to say to you?\"]\n",
    "    data_dic_list = []\n",
    "\n",
    "    for i, s in enumerate(samples):\n",
    "        # print(f\"In sample {i}/{len(samples)}: {s}\")\n",
    "        sample = s.strip()\n",
    "        sample = re.sub(r'[^\\w\\s]', '', sample)\n",
    "        word_list = sample.split(' ')\n",
    "        dic_entry_record, T_total, KS_total = Type_one_sentence(sample, L_min_w, k_look_w, p_max_w, L_min_s, k_look_s, p_max_s, R_rational, R_error, R_interrupt, T_event) # Take_average_of_one_sentence_result(1, sample)\n",
    "        data_dic = {\n",
    "            # settings\n",
    "            \"L_min_w\": float(L_min_w),\n",
    "            \"k_look_w\": float(k_look_w),\n",
    "            \"p_max_w\": float(p_max_w),\n",
    "            \"L_min_s\": float(L_min_s),\n",
    "            \"k_look_s\": float(k_look_s),\n",
    "            \"p_max_s\": float(p_max_s),\n",
    "            \"P_pred_w_c\": float(P_pred_w_c),\n",
    "            \"P_pred_w_n\": float(P_pred_w_n),\n",
    "            \"T_key\": float(T_key),\n",
    "            \"T_react_w\": float(T_react_w),\n",
    "            \"T_react_s\": float(T_react_s),\n",
    "            \"R_rational\": float(R_rational), # bounded rationality index\n",
    "            \"R_error\": float(R_error), # human error rate\n",
    "            \"R_interrupt\": float(R_interrupt), # interruption rate\n",
    "            \"T_event\": float(T_event), # interruption time\n",
    "\n",
    "            # results\n",
    "            \"sentence\": sample,\n",
    "            \"sentence_length\": int(len(sample)),\n",
    "            \"sentence_length_in_words\": int(len(word_list)),\n",
    "\n",
    "            \"T_total\": dic_entry_record['T_total'],\n",
    "            \"T_key_total\": dic_entry_record['T_key_total'],\n",
    "            \"T_react_w_total\": dic_entry_record['T_react_w_total'],\n",
    "            \"T_react_s_total\": dic_entry_record['T_react_s_total'],\n",
    "            \"T_react_total\": dic_entry_record['T_react_total'],\n",
    "            \"T_bounded_l_total\": dic_entry_record['T_bounded_l_total'],\n",
    "            \"T_bounded_w_total\": dic_entry_record['T_bounded_w_total'],\n",
    "            \"T_bounded_s_total\": dic_entry_record['T_bounded_s_total'],\n",
    "            \"T_error_total\": dic_entry_record['T_error_total'],\n",
    "            \"T_interrupt_total\": dic_entry_record['T_interrupt_total'],\n",
    "\n",
    "            \"T_event_total\": dic_entry_record['T_event_total'],\n",
    "            \"N_bounded_l_total\": dic_entry_record['N_bounded_l_total'],\n",
    "            \"N_bounded_w_total\": dic_entry_record['N_bounded_w_total'], \n",
    "            \"N_bounded_s_total\": dic_entry_record['N_bounded_s_total'], \n",
    "            \"N_bounded_total\": dic_entry_record['N_bounded_total'],\n",
    "\n",
    "            \"KS_total\": dic_entry_record['KS_total'],\n",
    "            \"KS_type_total\": dic_entry_record['KS_type_total'],\n",
    "            \"KS_select_total\": dic_entry_record['KS_select_total'],\n",
    "            \"KS_bounded_l_total\": dic_entry_record['KS_bounded_l_total'],\n",
    "            \"KS_bounded_w_total\": dic_entry_record['KS_bounded_w_total'],\n",
    "            \"KS_bounded_s_total\": dic_entry_record['KS_bounded_s_total'],\n",
    "            \"KS_error_total\": dic_entry_record['KS_error_total'],\n",
    "            \"KS_interrupt_total\": dic_entry_record['KS_interrupt_total'],\n",
    "\n",
    "            # basic statistics\n",
    "            \"entry_rate\": float(len(sample)/T_total)*12.0, # wpm\n",
    "            # \"effective_entry_rate\":\n",
    "            \"net_entry_rate\": float((len(sample)/T_total)*12.0 - (12.0/T_key)), # wpm\n",
    "            # \"net_effective_entry_rate\":\n",
    "            \"KS_saving\": float(float(len(sample)) - KS_total),\n",
    "            \"KS_saving_rate\": float(float(len(sample)) - KS_total)/float(len(sample)) # %\n",
    "        }\n",
    "\n",
    "        data_dic_list.append(data_dic)\n",
    "\n",
    "    # data_dic_list.sort(key=sort_by_sentence_length)\n",
    "\n",
    "    # Collect data\n",
    "    df_data_dic_list = pd.DataFrame(data=data_dic_list)\n",
    "\n",
    "    return df_data_dic_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: test Run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run condition A: No prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load initial parameters and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text entering strategy\n",
    "L_min_w = 100\n",
    "k_look_w = 0\n",
    "p_max_w = 0\n",
    "L_min_s = 100\n",
    "k_look_s = 0\n",
    "p_max_s = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Run_condition_A_all_data():\n",
    "    exp_result_dic_list = []\n",
    "    condition = \"A\"\n",
    "    for i in np.arange(2,10): # .1,0.1\n",
    "        for j in np.arange(0,4): # .1,0.1\n",
    "            data_frame = Run(SAMPLE_SIZE=100, CONDITION=condition, L_min_w=i, k_look_w=j)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'experiment_1_{condition}.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condition A: Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp_results = Run_condition_A_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_exp_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condition A: Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run condition AB: Word prediction only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load initial parameters and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text entering strategy\n",
    "L_min_w = 2 # 2-10\n",
    "k_look_w = 1 # 0-5\n",
    "p_max_w = 6\n",
    "L_min_s = 100\n",
    "k_look_s = 0\n",
    "p_max_s = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compare_condition_AB_all_data(condition):\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(2,10.1,0.1):\n",
    "        for j in np.arange(0,5.1,0.1):\n",
    "            data_frame = Run(SAMPLE_SIZE=100, CONDITION=condition, L_min_w=i, k_look_w=j, p_max_w=p_max_w)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'experiment_1_{condition}.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compare_condition_AB_p_L_all_data(condition):\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(2,10.1,0.1):\n",
    "        for j in np.arange(2,10.1,0.1):\n",
    "            data_frame = Run(SAMPLE_SIZE=100, CONDITION=condition, L_min_w=i, k_look_w=1, p_max_w=j)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'experiment_1_{condition}.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condition AB: Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOL_PRINT = False\n",
    "con_ab_df_exp_results = Compare_condition_AB_all_data('AB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOL_PRINT = False\n",
    "con_ab_df_exp_results = Compare_condition_AB_all_data('AB_current_w_only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOL_PRINT = False\n",
    "con_ab_df_exp_results = Compare_condition_AB_all_data('AB_next_w_only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOL_PRINT = False\n",
    "con_ab_df_exp_results = Compare_condition_AB_all_data('AB_current_w_only_ablebodied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOL_PRINT = False\n",
    "con_ab_p_L_df_exp_results = Compare_condition_AB_p_L_all_data('AB_p_L')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condition AB: Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "condition = 'AB'\n",
    "readname = f'experiment_1_{condition}.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "con_ab_df_exp_results_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "condition = 'AB_current_w_only'\n",
    "readname = f'experiment_1_{condition}.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "con_ab_c_only_df_exp_results_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "condition = 'AB_next_w_only'\n",
    "readname = f'experiment_1_{condition}.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "con_ab_n_only_df_exp_results_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "condition = 'AB_current_w_only_ablebodied'\n",
    "readname = f'experiment_1_{condition}.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "con_ab_c_only_ablebodied_df_exp_results_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "condition = 'AB_p_L'\n",
    "readname = f'experiment_1_{condition}.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "con_ab_df_exp_p_L_results_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Net_entry_rate: L_min_w & k_look_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and k_look_w\n",
    "con_ab_net_entry_rate_L_min_w_k_look_w = con_ab_df_exp_results_csv[['net_entry_rate', 'L_min_w', 'k_look_w']]\n",
    "vis_net_entry_rate_mean = con_ab_net_entry_rate_L_min_w_k_look_w.groupby(['L_min_w', 'k_look_w']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "# vis_net_entry_rate_std = con_ab_net_entry_rate_L_min_w_k_look_w.groupby(['L_min_w', 'k_look_w']).std()\n",
    "# vis_net_entry_rate_std = vis_net_entry_rate_std.reset_index()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('k_look_w', 'L_min_w', 'net_entry_rate')\n",
    "# pivot_table_std = vis_net_entry_rate_std.pivot('k_look_w', 'L_min_w', 'net_entry_rate')\n",
    "# print(pivot_table.shape)\n",
    "# print(pivot_table_std.shape)\n",
    "\n",
    "\n",
    "plt.xlabel('L_min_w', size=15)\n",
    "plt.ylabel('k_look_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(pivot_table_std)), cmap='coolwarm', interpolation='nearest') # x_stddev=.3,y_stddev=.3\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(0, 5, 6, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'exp1_L_k_ner.csv'\n",
    "outdir = './experiment_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and k_look_w for current word pred only\n",
    "con_ab_net_entry_rate_L_min_w_k_look_w = con_ab_c_only_df_exp_results_csv[['net_entry_rate', 'L_min_w', 'k_look_w']]\n",
    "vis_net_entry_rate_mean = con_ab_net_entry_rate_L_min_w_k_look_w.groupby(['L_min_w', 'k_look_w']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "# vis_net_entry_rate_std = con_ab_net_entry_rate_L_min_w_k_look_w.groupby(['L_min_w', 'k_look_w']).std()\n",
    "# vis_net_entry_rate_std = vis_net_entry_rate_std.reset_index()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('k_look_w', 'L_min_w', 'net_entry_rate')\n",
    "# pivot_table_std = vis_net_entry_rate_std.pivot('k_look_w', 'L_min_w', 'net_entry_rate')\n",
    "# print(pivot_table.shape)\n",
    "# print(pivot_table_std.shape)\n",
    "\n",
    "\n",
    "plt.xlabel('L_min_w', size=15)\n",
    "plt.ylabel('k_look_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(pivot_table_std)), cmap='coolwarm', interpolation='nearest') # x_stddev=.3,y_stddev=.3\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(0, 5, 6, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'exp1_AB_current_w_only_ablebodied_ner.csv'\n",
    "outdir = './experiment_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and k_look_w for next word pred only\n",
    "con_ab_net_entry_rate_L_min_w_k_look_w = con_ab_n_only_df_exp_results_csv[['net_entry_rate', 'L_min_w', 'k_look_w']]\n",
    "vis_net_entry_rate_mean = con_ab_net_entry_rate_L_min_w_k_look_w.groupby(['L_min_w', 'k_look_w']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "# vis_net_entry_rate_std = con_ab_net_entry_rate_L_min_w_k_look_w.groupby(['L_min_w', 'k_look_w']).std()\n",
    "# vis_net_entry_rate_std = vis_net_entry_rate_std.reset_index()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('k_look_w', 'L_min_w', 'net_entry_rate')\n",
    "# pivot_table_std = vis_net_entry_rate_std.pivot('k_look_w', 'L_min_w', 'net_entry_rate')\n",
    "# print(pivot_table.shape)\n",
    "# print(pivot_table_std.shape)\n",
    "\n",
    "\n",
    "plt.xlabel('L_min_w', size=15)\n",
    "plt.ylabel('k_look_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(pivot_table_std)), cmap='coolwarm', interpolation='nearest') # x_stddev=.3,y_stddev=.3\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(0, 5, 6, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and k_look_w for ablebodied\n",
    "con_ab_net_entry_rate_L_min_w_k_look_w = con_ab_c_only_ablebodied_df_exp_results_csv[['net_entry_rate', 'L_min_w', 'k_look_w']]\n",
    "vis_net_entry_rate_mean = con_ab_net_entry_rate_L_min_w_k_look_w.groupby(['L_min_w', 'k_look_w']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "# vis_net_entry_rate_std = con_ab_net_entry_rate_L_min_w_k_look_w.groupby(['L_min_w', 'k_look_w']).std()\n",
    "# vis_net_entry_rate_std = vis_net_entry_rate_std.reset_index()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('k_look_w', 'L_min_w', 'net_entry_rate')\n",
    "# pivot_table_std = vis_net_entry_rate_std.pivot('k_look_w', 'L_min_w', 'net_entry_rate')\n",
    "# print(pivot_table.shape)\n",
    "# print(pivot_table_std.shape)\n",
    "\n",
    "\n",
    "plt.xlabel('L_min_w', size=15)\n",
    "plt.ylabel('k_look_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(pivot_table_std)), cmap='coolwarm', interpolation='nearest') # x_stddev=.3,y_stddev=.3\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(0, 5, 6, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Net_entry_rate_std: L_min_w & k_look_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and k_look_w\n",
    "con_ab_net_entry_rate_L_min_w_k_look_w = con_ab_df_exp_results_csv[['net_entry_rate', 'L_min_w', 'k_look_w']]\n",
    "vis_net_entry_rate_std = con_ab_net_entry_rate_L_min_w_k_look_w.groupby(['L_min_w', 'k_look_w']).std()\n",
    "vis_net_entry_rate_std = vis_net_entry_rate_std.reset_index()\n",
    "\n",
    "# vis_net_entry_rate_std = con_ab_net_entry_rate_L_min_w_k_look_w.groupby(['L_min_w', 'k_look_w']).std()\n",
    "# vis_net_entry_rate_std = vis_net_entry_rate_std.reset_index()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_std.pivot('k_look_w', 'L_min_w', 'net_entry_rate')\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('L_min_w', size=15)\n",
    "plt.ylabel('k_look_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(pivot_table_std)), cmap='coolwarm', interpolation='nearest') # x_stddev=.3,y_stddev=.3\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(0, 5, 6, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### p_max_w VS L_min_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# evaluate L_min_w and p_max_w\n",
    "con_ab_net_entry_rate_L_min_w_k_look_w = con_ab_df_exp_p_L_results_csv[['net_entry_rate', 'L_min_w', 'p_max_w']]\n",
    "vis_net_entry_rate_mean = con_ab_net_entry_rate_L_min_w_k_look_w.groupby(['L_min_w', 'p_max_w']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "# vis_net_entry_rate_std = con_ab_net_entry_rate_L_min_w_k_look_w.groupby(['L_min_w', 'k_look_w']).std()\n",
    "# vis_net_entry_rate_std = vis_net_entry_rate_std.reset_index()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('p_max_w', 'L_min_w', 'net_entry_rate')\n",
    "# pivot_table_std = vis_net_entry_rate_std.pivot('k_look_w', 'L_min_w', 'net_entry_rate')\n",
    "# print(pivot_table.shape)\n",
    "# print(pivot_table_std.shape)\n",
    "\n",
    "\n",
    "plt.xlabel('L_min_w', size=15)\n",
    "plt.ylabel('p_max_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(pivot_table_std)), cmap='coolwarm', interpolation='nearest') # x_stddev=.3,y_stddev=.3\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "plt.colorbar()\n",
    "\n",
    "# table = pd.pivot_table(pivot_table, index='p_max_w', values='L_min_w', aggfunc=[np.max, np.min])\n",
    "\n",
    "# print(f\"{pivot_table}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For able-bodied users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User profile\n",
    "T_key =  0.26 # 0.26 # 0.6\n",
    "T_react_w = 0.45 # 0.45 # 1.20\n",
    "T_react_s = 1.90 # T_react_w * L_s_ave = 1.20*4.23 = 5.08\n",
    "\n",
    "R_rational = 1\n",
    "R_error = 0\n",
    "R_interrupt = 0\n",
    "\n",
    "T_event = 0\n",
    "\n",
    "def T_interrupt(T_event): # the probability of the system have correct sentence predictions\n",
    "    a=0.189\n",
    "    c=1.03\n",
    "    return 0\n",
    "\n",
    "# Word prediction settings\n",
    "P_pred_w_c = 1 # 0.6 # KWickChat\n",
    "P_pred_w_n = 1 # 0.5 # KWickChat\n",
    "\n",
    "# Sentence prediction settings\n",
    "def P_pred_s(current_word_index, L_s): # the probability of the system have correct sentence predictions\n",
    "    a=1\n",
    "    b=L_s\n",
    "    x=current_word_index\n",
    "    c=0\n",
    "    return a*math.log(x+1,b)+c\n",
    "\n",
    "# Text entering strategy\n",
    "L_min_w = 2 # 2-10\n",
    "k_look_w = 0 # 0-5\n",
    "p_max_w = 6\n",
    "L_min_s = 100\n",
    "k_look_s = 0\n",
    "p_max_s = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_ab_df_exp_results_ablebodied = Compare_condition_AB_all_data('AB_ablebodied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and k_look_w\n",
    "con_ab_net_entry_rate_L_min_w_k_look_w = con_ab_df_exp_results_ablebodied[['net_entry_rate', 'L_min_w', 'k_look_w']]\n",
    "vis_net_entry_rate_mean = con_ab_net_entry_rate_L_min_w_k_look_w.groupby(['L_min_w', 'k_look_w']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('k_look_w', 'L_min_w', 'net_entry_rate')\n",
    "\n",
    "plt.xlabel('L_min_w', size=15)\n",
    "plt.ylabel('k_look_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(pivot_table_std)), cmap='coolwarm', interpolation='nearest') # x_stddev=.3,y_stddev=.3\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(0, 5, 6, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### net_entry_rate: sentence_length_in_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate net_entry_rate and sentence_length_in_words\n",
    "con_ab_net_entry_rate_L_min_w_k_look_w = con_ab_df_exp_results_csv[['net_entry_rate', 'L_min_w', 'sentence_length_in_words']]\n",
    "con_ab_net_entry_rate_mean_L_min_w = con_ab_net_entry_rate_L_min_w_k_look_w.groupby(['L_min_w', 'sentence_length_in_words']).mean()\n",
    "vis_net_entry_rate_mean = con_ab_net_entry_rate_mean_L_min_w.groupby(['sentence_length_in_words']).mean()\n",
    "# vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "# pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'sentence_length', 'net_entry_rate')\n",
    "plt.xlabel('sentence_length_in_words', size=15)\n",
    "plt.ylabel('net_entry_rate_mean', size=15)\n",
    "plt.plot(vis_net_entry_rate_mean)\n",
    "plt.axhline(y=0, color='k', linestyle='--')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KS_saving_rate: L_min_w & k_look_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and k_look_w\n",
    "con_ab_KS_saving_rate_L_min_w_k_look_w = con_ab_df_exp_results_csv[['KS_saving_rate', 'L_min_w', 'k_look_w']]\n",
    "vis_KS_saving_rate_mean = con_ab_KS_saving_rate_L_min_w_k_look_w.groupby(['L_min_w', 'k_look_w']).mean()\n",
    "vis_KS_saving_rate_mean = vis_KS_saving_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_KS_saving_rate_mean.pivot('k_look_w', 'L_min_w', 'KS_saving_rate')\n",
    "plt.xlabel('L_min_w', size=15)\n",
    "plt.ylabel('k_look_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.4,y_stddev=.4)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(0, 5, 6, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cb.get_ticks()])\n",
    "# plt.colorbar(['{:.0f}%'.format(x) for x in np.arange(vis_KS_saving_rate_mean['KS_saving_rate'].min(), vis_KS_saving_rate_mean['KS_saving_rate'].max(), 10)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KS_saving_rate_std: L_min_w & k_min_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and k_look_w\n",
    "con_ab_KS_saving_rate_L_min_w_k_look_w = con_ab_df_exp_results_csv[['KS_saving_rate', 'L_min_w', 'k_look_w']]\n",
    "vis_KS_saving_rate_std = con_ab_KS_saving_rate_L_min_w_k_look_w.groupby(['L_min_w', 'k_look_w']).std()\n",
    "vis_KS_saving_rate_std = vis_KS_saving_rate_std.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_KS_saving_rate_std.pivot('k_look_w', 'L_min_w', 'KS_saving_rate')\n",
    "plt.xlabel('L_min_w', size=15)\n",
    "plt.ylabel('k_look_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.4,y_stddev=.4)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(0, 5, 6, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cb.get_ticks()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KS_saving_rate & sentence_length_in_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate KS_saving_rate and sentence_length_in_words\n",
    "con_ab_KS_saving_rate_L_min_w_k_look_w = con_ab_df_exp_results_csv[['KS_saving_rate', 'L_min_w', 'sentence_length_in_words']]\n",
    "con_ab_KS_saving_rate_mean_L_min_w = con_ab_KS_saving_rate_L_min_w_k_look_w.groupby(['L_min_w', 'sentence_length_in_words']).mean()\n",
    "vis_KS_saving_rate_mean = con_ab_KS_saving_rate_mean_L_min_w.groupby(['sentence_length_in_words']).mean()\n",
    "# vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "# pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'sentence_length', 'net_entry_rate')\n",
    "plt.xlabel('sentence_length_in_words', size=15)\n",
    "plt.ylabel('KS_saving_rate_mean (%)', size=15)\n",
    "plt.plot(vis_KS_saving_rate_mean, label=\"KS saving rate\")\n",
    "KS_saving_rate_mean_mean = vis_KS_saving_rate_mean['KS_saving_rate'].mean()\n",
    "# print(vis_KS_saving_rate_mean)\n",
    "plt.axhline(y=KS_saving_rate_mean_mean, color='k', linestyle='--', label='average KS saving rate')\n",
    "plt.legend(loc = 'upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condition AC: Sentence prediction only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load initial parameters and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text entering strategy\n",
    "L_min_w = 100 \n",
    "k_look_w = 0 \n",
    "p_max_w = 0\n",
    "L_min_s = 2 # 2-10\n",
    "k_look_s = 2 # 0-5\n",
    "p_max_s = 6 # 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compare_condition_AC_all_data(condition):\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(2,10.1,0.1):\n",
    "        for j in np.arange(0,5.1,0.1):\n",
    "            data_frame = Run(SAMPLE_SIZE=100, CONDITION=condition, L_min_s=i, k_look_s=j, p_max_s=6)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'experiment_1_{condition}.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compare_condition_AC_p_L_all_data(condition):\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(2,10.1,0.1):\n",
    "        for j in np.arange(2,10.1,0.1):\n",
    "            data_frame = Run(SAMPLE_SIZE=100, CONDITION=condition, L_min_s=i, k_look_s=1, p_max_s=j)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'experiment_1_{condition}.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condition AC: Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOL_PRINT = False\n",
    "con_ac_df_exp_results = Compare_condition_AC_all_data('AC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOL_PRINT = False\n",
    "con_ac_df_exp_p_L_results_csv = Compare_condition_AC_p_L_all_data('AC_p_L')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condition AC: Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "condition = 'AC'\n",
    "readname = f'experiment_1_{condition}.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "con_ac_df_exp_results_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "condition = 'AC_p_L'\n",
    "readname = f'experiment_1_{condition}.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "con_ac_df_exp_p_L_results_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### L_min_s & k_look_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and k_look_w\n",
    "con_ac_net_entry_rate_L_min_s_k_look_s = con_ac_df_exp_results_csv[['net_entry_rate', 'L_min_s', 'k_look_s']]\n",
    "vis_net_entry_rate_mean = con_ac_net_entry_rate_L_min_s_k_look_s.groupby(['L_min_s', 'k_look_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('k_look_s', 'L_min_s', 'net_entry_rate')\n",
    "plt.xlabel('L_min_s', size=15)\n",
    "plt.ylabel('k_look_s', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.4,y_stddev=.4)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(0, 5, 6, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and k_look_w\n",
    "con_ac_net_entry_rate_L_min_s_k_look_s = con_ac_df_exp_results_csv[['KS_saving_rate', 'L_min_s', 'k_look_s']]\n",
    "vis_net_entry_rate_mean = con_ac_net_entry_rate_L_min_s_k_look_s.groupby(['L_min_s', 'k_look_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('k_look_s', 'L_min_s', 'KS_saving_rate')\n",
    "plt.xlabel('L_min_s', size=15)\n",
    "plt.ylabel('k_look_s', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.4,y_stddev=.4)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(0, 5, 6, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and k_look_w\n",
    "con_ac_net_entry_rate_L_min_s_k_look_s = con_ac_df_exp_results_csv[['net_entry_rate', 'L_min_s', 'k_look_s']]\n",
    "vis_net_entry_rate_mean = con_ac_net_entry_rate_L_min_s_k_look_s.groupby(['L_min_s', 'k_look_s']).std()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('k_look_s', 'L_min_s', 'net_entry_rate')\n",
    "plt.xlabel('L_min_s', size=15)\n",
    "plt.ylabel('k_look_s', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.4,y_stddev=.4)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(0, 5, 6, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "plt.colorbar()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### p_max_s & L_min_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_s and p_max_s\n",
    "con_ac_net_entry_rate_L_min_s_k_look_s = con_ac_df_exp_p_L_results_csv[['net_entry_rate', 'L_min_s', 'p_max_s']]\n",
    "vis_net_entry_rate_mean = con_ac_net_entry_rate_L_min_s_k_look_s.groupby(['L_min_s', 'p_max_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('p_max_s', 'L_min_s', 'net_entry_rate')\n",
    "plt.xlabel('L_min_s', size=15)\n",
    "plt.ylabel('p_max_s', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.4,y_stddev=.4)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_s and p_max_s\n",
    "con_ac_net_entry_rate_L_min_s_k_look_s = con_ac_df_exp_p_L_results_csv[['net_entry_rate', 'L_min_s', 'p_max_s']]\n",
    "vis_net_entry_rate_mean = con_ac_net_entry_rate_L_min_s_k_look_s.groupby(['L_min_s', 'p_max_s']).std()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('p_max_s', 'L_min_s', 'net_entry_rate')\n",
    "plt.xlabel('L_min_s', size=15)\n",
    "plt.ylabel('p_max_s', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.4,y_stddev=.4)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### net_entry_rate & sentence_length_in_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate net_entry_rate and sentence_length_in_words\n",
    "con_ac_net_entry_rate_L_min_s_k_look_s = con_ac_df_exp_results_csv[['net_entry_rate', 'L_min_s', 'sentence_length_in_words']] # _in_words\n",
    "con_ac_net_entry_rate_mean_L_min_s = con_ac_net_entry_rate_L_min_s_k_look_s.groupby(['L_min_s', 'sentence_length_in_words']).mean()\n",
    "vis_net_entry_rate_mean = con_ac_net_entry_rate_mean_L_min_s.groupby(['sentence_length_in_words']).mean()\n",
    "# vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "# pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'sentence_length', 'net_entry_rate')\n",
    "plt.xlabel('sentence_length_in_words', size=15)\n",
    "plt.ylabel('net_entry_rate_mean', size=15)\n",
    "plt.plot(vis_net_entry_rate_mean)\n",
    "plt.axhline(y=0, color='k', linestyle='--')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### net_entry_rate & sentence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate net_entry_rate and sentence_length_in_words\n",
    "con_ac_net_entry_rate_L_min_s_k_look_s = con_ac_df_exp_results_csv[['net_entry_rate', 'L_min_s', 'sentence_length']] # _in_words\n",
    "con_ac_net_entry_rate_mean_L_min_s = con_ac_net_entry_rate_L_min_s_k_look_s.groupby(['L_min_s', 'sentence_length']).mean()\n",
    "vis_net_entry_rate_mean = con_ac_net_entry_rate_mean_L_min_s.groupby(['sentence_length']).mean()\n",
    "# vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "# pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'sentence_length', 'net_entry_rate')\n",
    "plt.xlabel('sentence_length', size=15)\n",
    "plt.ylabel('net_entry_rate_mean', size=15)\n",
    "plt.plot(vis_net_entry_rate_mean)\n",
    "plt.axhline(y=0, color='k', linestyle='--')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KS_saving_rate & sentence_length_in_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate KS_saving_rate and sentence_length_in_words\n",
    "con_ac_KS_saving_rate_L_min_s_k_look_s = con_ac_df_exp_results_csv[['KS_saving_rate', 'L_min_s', 'sentence_length_in_words']]\n",
    "con_ac_KS_saving_rate_mean_L_min_s = con_ac_KS_saving_rate_L_min_s_k_look_s.groupby(['L_min_s', 'sentence_length_in_words']).mean()\n",
    "vis_KS_saving_rate_mean = con_ac_KS_saving_rate_mean_L_min_s.groupby(['sentence_length_in_words']).mean()\n",
    "# vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "# pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'sentence_length', 'net_entry_rate')\n",
    "plt.xlabel('sentence_length_in_words', size=15)\n",
    "plt.ylabel('KS_saving_rate_mean', size=15)\n",
    "plt.plot(vis_KS_saving_rate_mean, label=\"KS saving rate\")\n",
    "KS_saving_rate_mean_mean = vis_KS_saving_rate_mean['KS_saving_rate'].mean()\n",
    "# print(vis_KS_saving_rate_mean)\n",
    "plt.axhline(y=KS_saving_rate_mean_mean, color='k', linestyle='--', label='average KS saving rate')\n",
    "plt.legend(loc = 'upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KS_saving_rate & sentence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate KS_saving_rate and sentence_length_in_words\n",
    "con_ac_KS_saving_rate_L_min_s_k_look_s = con_ac_df_exp_results_csv[['KS_saving_rate', 'L_min_s', 'sentence_length']]\n",
    "con_ac_KS_saving_rate_mean_L_min_s = con_ac_KS_saving_rate_L_min_s_k_look_s.groupby(['L_min_s', 'sentence_length']).mean()\n",
    "vis_KS_saving_rate_mean = con_ac_KS_saving_rate_mean_L_min_s.groupby(['sentence_length']).mean()\n",
    "# vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "# pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'sentence_length', 'net_entry_rate')\n",
    "plt.xlabel('sentence_length', size=15)\n",
    "plt.ylabel('KS_saving_rate_mean (%)', size=15)\n",
    "plt.plot(vis_KS_saving_rate_mean, label=\"KS saving rate\")\n",
    "KS_saving_rate_mean_mean = vis_KS_saving_rate_mean['KS_saving_rate'].mean()\n",
    "# print(vis_KS_saving_rate_mean)\n",
    "plt.axhline(y=KS_saving_rate_mean_mean, color='k', linestyle='--', label='average KS saving rate')\n",
    "plt.legend(loc = 'upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condition AD: Word prediction + sentence prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load initial parameters and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text entering strategy\n",
    "L_min_w = 4 # 2-10\n",
    "k_look_w = 1 \n",
    "p_max_w = 6\n",
    "L_min_s = 5 # 2-10\n",
    "k_look_s = 1\n",
    "p_max_s = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compare_condition_AD_all_data(condition):\n",
    "    # condition = \"AD\"\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(2,10.1,0.1):\n",
    "        for j in np.arange(2,10.1,0.1):\n",
    "            data_frame = Run(SAMPLE_SIZE=100, CONDITION=condition, L_min_w=i, k_look_w=k_look_w, p_max_w=p_max_w, L_min_s=j, k_look_s=k_look_s, p_max_s=p_max_s)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'experiment_1_{condition}.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_1_con_ad_p_L_df_results_csv(condition):\n",
    "    # condition = \"AD\"\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(2,10.1,0.1):\n",
    "        for j in np.arange(2,10.1,0.1):\n",
    "            data_frame = Run(SAMPLE_SIZE=100, CONDITION=condition, L_min_w=L_min_w, k_look_w=k_look_w, p_max_w=p_max_w, L_min_s=i, k_look_s=k_look_s, p_max_s=j)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'experiment_1_{condition}.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_1_con_ad_L_k_df_results_csv(condition):\n",
    "    # condition = \"AD\"\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(2,10.1,0.1):\n",
    "        for j in np.arange(0,5.1,0.1):\n",
    "            data_frame = Run(SAMPLE_SIZE=100, CONDITION=condition, L_min_w=L_min_w, k_look_w=k_look_w, p_max_w=p_max_w, L_min_s=i, k_look_s=j, p_max_s=p_max_s)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'experiment_1_{condition}.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condition AD: Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_1_con_ad_df_exp_results = Compare_condition_AD_all_data('AD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_1_con_ad_p_L_df_exp_results = exp_1_con_ad_p_L_df_results_csv('AD_p_L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_1_con_ad_L_k_df_exp_results = exp_1_con_ad_L_k_df_results_csv('AD_L_k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condition AD: Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "condition = 'AD'\n",
    "readname = f'experiment_1_{condition}.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "exp_1_con_ad_df_results_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "condition = 'AD_p_L'\n",
    "readname = f'experiment_1_{condition}.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "exp_1_con_ad_p_l_df_results_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "condition = 'AD_L_k'\n",
    "readname = f'experiment_1_{condition}.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "exp_1_con_ad_l_k_df_results_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### L_min_w & L_min_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s\n",
    "con_ad_net_entry_rate_L_min_w_L_min_s = exp_1_con_ad_df_results_csv[['net_entry_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = con_ad_net_entry_rate_L_min_w_L_min_s.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'net_entry_rate')\n",
    "plt.xlabel('L_min_s', size=15)\n",
    "plt.ylabel('L_min_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.5,y_stddev=.5)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and k_look_w\n",
    "con_ad_net_entry_rate_L_min_w_L_min_s = exp_1_con_ad_df_results_csv[['net_entry_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = con_ad_net_entry_rate_L_min_w_L_min_s.groupby(['L_min_w', 'L_min_s']).std()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'net_entry_rate')\n",
    "plt.xlabel('L_min_s', size=15)\n",
    "plt.ylabel('L_min_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.4,y_stddev=.4)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### standard deviation & sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_entry_rate = exp_1_con_ad_df_results_csv[['sentence_length_in_words', 'net_entry_rate']]\n",
    "net_entry_rate_std = net_entry_rate.groupby(['sentence_length_in_words']).mean()\n",
    "print(net_entry_rate_std)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "# pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'sentence_length', 'net_entry_rate')\n",
    "plt.xlabel('sentence_length_in_words', size=15)\n",
    "plt.ylabel('net_entry_rate', size=15)\n",
    "plt.plot(net_entry_rate_std, label='net entry rate')\n",
    "# plt.axhline(y=net_entry_rate_std['net_entry_rate'].mean(), color='k', linestyle='--', label='average of net entry rate')\n",
    "plt.axvline(x=4.23, color='k', linestyle='--', label='average sentence length')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and k_look_w\n",
    "con_ad_net_entry_rate_L_min_w_L_min_s = exp_1_con_ad_df_results_csv[['KS_saving_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = con_ad_net_entry_rate_L_min_w_L_min_s.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'KS_saving_rate')\n",
    "plt.xlabel('L_min_s', size=15)\n",
    "plt.ylabel('L_min_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.4,y_stddev=.4)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cb.get_ticks()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and k_look_w\n",
    "con_ad_net_entry_rate_L_min_w_L_min_s = exp_1_con_ad_df_results_csv[['KS_saving_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = con_ad_net_entry_rate_L_min_w_L_min_s.groupby(['L_min_w', 'L_min_s']).std()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'KS_saving_rate')\n",
    "plt.xlabel('L_min_s', size=15)\n",
    "plt.ylabel('L_min_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.4,y_stddev=.4)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "cb = plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### L_min_s & p_max_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s\n",
    "con_ad_net_entry_rate_L_min_w_L_min_s = exp_1_con_ad_p_l_df_results_csv[['net_entry_rate', 'p_max_s', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = con_ad_net_entry_rate_L_min_w_L_min_s.groupby(['p_max_s', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('p_max_s', 'L_min_s', 'net_entry_rate')\n",
    "plt.xlabel('L_min_s', size=15)\n",
    "plt.ylabel('p_max_s', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.5,y_stddev=.5)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### L & k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate k_look_s and L_min_s\n",
    "con_ad_net_entry_rate_L_min_w_L_min_s = exp_1_con_ad_l_k_df_results_csv[['net_entry_rate', 'L_min_s', 'k_look_s']]\n",
    "vis_net_entry_rate_mean = con_ad_net_entry_rate_L_min_w_L_min_s.groupby(['L_min_s', 'k_look_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('k_look_s', 'L_min_s', 'net_entry_rate')\n",
    "plt.xlabel('L_min_s', size=15)\n",
    "plt.ylabel('k_look_s', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.5,y_stddev=.5)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(0, 5, 6, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "plt.colorbar()\n",
    "\n",
    "\n",
    "# # evaluate L_min_s and p_max_s\n",
    "# con_ac_net_entry_rate_L_min_s_k_look_s = con_ac_df_exp_p_L_results_csv[['net_entry_rate', 'L_min_s', 'p_max_s']]\n",
    "# vis_net_entry_rate_mean = con_ac_net_entry_rate_L_min_s_k_look_s.groupby(['L_min_s', 'p_max_s']).mean()\n",
    "# vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10,5))\n",
    "# pivot_table = vis_net_entry_rate_mean.pivot('p_max_s', 'L_min_s', 'net_entry_rate')\n",
    "# plt.xlabel('L_min_s', size=15)\n",
    "# plt.ylabel('p_max_s', size=15)\n",
    "# plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# # plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.4,y_stddev=.4)), cmap='coolwarm', interpolation='nearest')\n",
    "# ax.invert_yaxis()\n",
    "# ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "# xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "# ax.set_xticklabels(xticks)\n",
    "# ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "# yticks = np.linspace(1, 6, 6, dtype=np.int16)\n",
    "# ax.set_yticklabels(yticks)\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### net_entry_rate & sentence_length_in_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate net_entry_rate and sentence_length_in_words\n",
    "con_ad_net_entry_rate_L_min_s_k_look_s = exp_1_con_ad_df_results_csv[['net_entry_rate', 'L_min_s', 'sentence_length_in_words']] # _in_words\n",
    "con_ad_net_entry_rate_mean_L_min_s = con_ad_net_entry_rate_L_min_s_k_look_s.groupby(['L_min_s', 'sentence_length_in_words']).mean()\n",
    "vis_net_entry_rate_mean = con_ad_net_entry_rate_mean_L_min_s.groupby(['sentence_length_in_words']).mean()\n",
    "# vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "# pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'sentence_length', 'net_entry_rate')\n",
    "plt.xlabel('sentence_length_in_words', size=15)\n",
    "plt.ylabel('net_entry_rate_mean', size=15)\n",
    "plt.plot(vis_net_entry_rate_mean)\n",
    "plt.axhline(y=0, color='k', linestyle='--')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### net_entry_rate & sentence_length_in_words std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate net_entry_rate and sentence_length_in_words\n",
    "con_ad_net_entry_rate_L_min_s_k_look_s = exp_1_con_ad_df_results_csv[['net_entry_rate', 'L_min_s', 'sentence_length_in_words']] # _in_words\n",
    "con_ad_net_entry_rate_mean_L_min_s = con_ad_net_entry_rate_L_min_s_k_look_s.groupby(['L_min_s', 'sentence_length_in_words']).mean()\n",
    "vis_net_entry_rate_mean = con_ad_net_entry_rate_mean_L_min_s.groupby(['sentence_length_in_words']).std()\n",
    "# vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "# pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'sentence_length', 'net_entry_rate')\n",
    "plt.xlabel('sentence_length_in_words', size=15)\n",
    "plt.ylabel('net_entry_rate_mean', size=15)\n",
    "plt.plot(vis_net_entry_rate_mean)\n",
    "plt.axhline(y=0, color='k', linestyle='--')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KS_saving_rate & sentence_length_in_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate KS_saving_rate and sentence_length_in_words\n",
    "con_ad_KS_saving_rate_L_min_s_k_look_s = exp_1_con_ad_df_results_csv[['KS_saving_rate', 'L_min_s', 'sentence_length_in_words']]\n",
    "con_ad_KS_saving_rate_mean_L_min_s = con_ad_KS_saving_rate_L_min_s_k_look_s.groupby(['L_min_s', 'sentence_length_in_words']).mean()\n",
    "vis_KS_saving_rate_mean = con_ad_KS_saving_rate_mean_L_min_s.groupby(['sentence_length_in_words']).mean()\n",
    "# vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "# pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'sentence_length', 'net_entry_rate')\n",
    "plt.xlabel('sentence_length_in_words', size=15)\n",
    "plt.ylabel('KS_saving_rate_mean', size=15)\n",
    "plt.plot(vis_KS_saving_rate_mean, label=\"KS saving rate\")\n",
    "KS_saving_rate_mean_mean = vis_KS_saving_rate_mean['KS_saving_rate'].mean()\n",
    "# print(vis_KS_saving_rate_mean)\n",
    "plt.axhline(y=KS_saving_rate_mean_mean, color='k', linestyle='--', label='average KS saving rate')\n",
    "plt.legend(loc = 'upper right')\n",
    "\n",
    "vals = ax.get_yticks()\n",
    "ax.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KS_saving_rate & sentence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate KS_saving_rate and sentence_length_in_words\n",
    "con_ad_KS_saving_rate_L_min_s_k_look_s = exp_1_con_ad_df_results_csv[['KS_saving_rate', 'L_min_s', 'sentence_length']]\n",
    "con_ad_KS_saving_rate_mean_L_min_s = con_ad_KS_saving_rate_L_min_s_k_look_s.groupby(['L_min_s', 'sentence_length']).mean()\n",
    "vis_KS_saving_rate_mean = con_ad_KS_saving_rate_mean_L_min_s.groupby(['sentence_length']).mean()\n",
    "# vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "# pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'sentence_length', 'net_entry_rate')\n",
    "plt.xlabel('sentence_length', size=15)\n",
    "plt.ylabel('KS_saving_rate_mean (%)', size=15)\n",
    "plt.plot(vis_KS_saving_rate_mean, label=\"KS saving rate\")\n",
    "KS_saving_rate_mean_mean = vis_KS_saving_rate_mean['KS_saving_rate'].mean()\n",
    "# print(vis_KS_saving_rate_mean)\n",
    "plt.axhline(y=KS_saving_rate_mean_mean, color='k', linestyle='--', label='average KS saving rate')\n",
    "plt.legend(loc = 'upper right')\n",
    "vals = ax.get_yticks()\n",
    "ax.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When sentence_length_in_words = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_ad_sen_len_eq_6 = exp_1_con_ad_df_results_csv.loc[exp_1_con_ad_df_results_csv['sentence_length_in_words']==6]\n",
    "# print(con_ad_sen_len_eq_6)\n",
    "vis_net_entry_rate_mean = con_ad_net_entry_rate_L_min_w_L_min_s.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'net_entry_rate')\n",
    "plt.xlabel('L_min_w', size=15)\n",
    "plt.ylabel('L_min_s', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.4,y_stddev=.4)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_ad_sen_len_eq_6 = con_ad_df_exp_results_csv.loc[con_ad_df_exp_results_csv['sentence_length_in_words']==6]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### difference between AAC and able-bodied in entry rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User profile: T_aac - T_able\n",
    "T_key =  0.34 # \n",
    "T_react_w = 0.75 # 0.45 # 1.20\n",
    "T_react_s = 3.39 # T_react_w * L_s_ave = 1.20*4.52 = 5.42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_ad_df_exp_results_diff = Compare_condition_AD_all_data('AD-diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "condition = 'AD-diff'\n",
    "readname = f'experiment_1_{condition}.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "con_ad_diff_df_exp_results_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate net_entry_rate and sentence_length_in_words\n",
    "con_ad_net_entry_rate_L_min_s_k_look_s = con_ad_diff_df_exp_results_csv[['entry_rate', 'sentence_length']] # _in_words\n",
    "vis_net_entry_rate_mean = con_ad_net_entry_rate_L_min_s_k_look_s.groupby(['sentence_length']).mean()\n",
    "# vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "# pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'sentence_length', 'net_entry_rate')\n",
    "plt.xlabel('sentence_length (characters)', size=15)\n",
    "plt.ylabel('entry_rate_diff (Able-bodied_entry_rate - AAC_entry_rate)', size=15)\n",
    "plt.plot(vis_net_entry_rate_mean)\n",
    "plt.axhline(y=0, color='k', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condition AD-k: Best word pred settings for sentence pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load initial parameters and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text entering strategy\n",
    "L_min_w = 7 # \n",
    "k_look_w = 0 # 0-5\n",
    "p_max_w = 6\n",
    "L_min_s = 5\n",
    "k_look_s = 0 # 0-5\n",
    "p_max_s = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compare_condition_AD_k_all_data(condition):\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(0,5.1,0.1):\n",
    "        for j in np.arange(0,5.1,0.1):\n",
    "            data_frame = Run(SAMPLE_SIZE=100, CONDITION=condition, L_min_w=L_min_w, k_look_w=i, p_max_w=p_max_w, L_min_s=L_min_s, k_look_s=j, p_max_s=p_max_s)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'experiment_1_{condition}.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_ad_k_df_exp_results = Compare_condition_AD_k_all_data('AD_k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "condition = 'AD_K'\n",
    "readname = f'experiment_1_{condition}.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "con_ad_k_df_exp_results_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### L_min_w & k_look_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate k_look_s and k_look_w\n",
    "con_ad_k_net_entry_rate_L_min_s_L_min_w = con_ad_k_df_exp_results_csv[['net_entry_rate', 'k_look_s', 'k_look_w']]\n",
    "vis_net_entry_rate_mean = con_ad_k_net_entry_rate_L_min_s_L_min_w.groupby(['k_look_s', 'k_look_w']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('k_look_w', 'k_look_s', 'net_entry_rate')\n",
    "plt.xlabel('k_look_s', size=15)\n",
    "plt.ylabel('k_look_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.4,y_stddev=.4)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(0, 5, 6, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(0, 5, 6, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and k_look_w\n",
    "con_ad_k_net_entry_rate_L_min_s_L_min_w = con_ad_k_df_exp_results_csv[['net_entry_rate', 'k_look_s', 'k_look_w']]\n",
    "vis_net_entry_rate_mean = con_ad_k_net_entry_rate_L_min_s_L_min_w.groupby(['k_look_s', 'k_look_w']).std()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('k_look_w', 'k_look_s', 'net_entry_rate')\n",
    "plt.xlabel('k_look_s', size=15)\n",
    "plt.ylabel('k_look_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.4,y_stddev=.4)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(0, 5, 6, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(0, 5, 6, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate k_look_s and k_look_w\n",
    "con_ad_k_KS_saving_rate_k_look_s_k_look_w = con_ad_k_df_exp_results_csv[['KS_saving_rate', 'k_look_s', 'k_look_w']]\n",
    "vis_KS_saving_rate_mean = con_ad_k_KS_saving_rate_k_look_s_k_look_w.groupby(['k_look_s', 'k_look_w']).mean()\n",
    "vis_KS_saving_rate_mean = vis_KS_saving_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_KS_saving_rate_mean.pivot('k_look_w', 'k_look_s', 'KS_saving_rate')\n",
    "plt.xlabel('k_look_s', size=15)\n",
    "plt.ylabel('k_look_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.4,y_stddev=.4)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(0, 5, 6, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(0, 5, 6, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cb.get_ticks()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: KLM-BEI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load fundamental function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Run_exp_2(SAMPLE_SIZE, CONDITION, R_rational, R_error, R_interrupt, T_event, L_min_w=100.0, k_look_w=0.0, p_max_w=0.0, L_min_s=100.0, k_look_s=0.0, p_max_s=0.0):\n",
    "    with open(f'aac_daily_conversation_sample_{SAMPLE_SIZE}.txt') as file:\n",
    "        samples = file.readlines()\n",
    "    # samples = [\"Oh so what did dad have to say to you?\"]\n",
    "    data_dic_list = []\n",
    "\n",
    "    for i, s in enumerate(samples):\n",
    "        # print(f\"In sample {i}/{len(samples)}: {s}\")\n",
    "        sample = s.strip()\n",
    "        sample = re.sub(r'[^\\w\\s]', '', sample)\n",
    "        word_list = sample.split(' ')\n",
    "        dic_entry_record, T_total, KS_total = Type_one_sentence(sample, L_min_w, k_look_w, p_max_w, L_min_s, k_look_s, p_max_s, R_rational=R_rational, R_error=R_error, R_interrupt=R_interrupt, T_event=T_event) # Take_average_of_one_sentence_result(1, sample)\n",
    "        data_dic = {\n",
    "            # settings\n",
    "            \"L_min_w\": float(L_min_w),\n",
    "            \"k_look_w\": float(k_look_w),\n",
    "            \"p_max_w\": float(p_max_w),\n",
    "            \"L_min_s\": float(L_min_s),\n",
    "            \"k_look_s\": float(k_look_s),\n",
    "            \"p_max_s\": float(p_max_s),\n",
    "            \"P_pred_w_c\": float(P_pred_w_c),\n",
    "            \"P_pred_w_n\": float(P_pred_w_n),\n",
    "            \"T_key\": float(T_key),\n",
    "            \"T_react_w\": float(T_react_w),\n",
    "            \"T_react_s\": float(T_react_s),\n",
    "            \"R_rational\": float(R_rational), # bounded rationality index\n",
    "            \"R_error\": float(R_error), # human error rate\n",
    "            \"R_interrupt\": float(R_interrupt), # interruption rate\n",
    "            \"T_event\": float(T_event), # interruption time\n",
    "\n",
    "            # results\n",
    "            \"sentence\": sample,\n",
    "            \"sentence_length\": int(len(sample)),\n",
    "            \"sentence_length_in_words\": int(len(word_list)),\n",
    "\n",
    "            \"T_total\": dic_entry_record['T_total'],\n",
    "            \"T_key_total\": dic_entry_record['T_key_total'],\n",
    "            \"T_react_w_total\": dic_entry_record['T_react_w_total'],\n",
    "            \"T_react_s_total\": dic_entry_record['T_react_s_total'],\n",
    "            \"T_react_total\": dic_entry_record['T_react_total'],\n",
    "            \"T_bounded_l_total\": dic_entry_record['T_bounded_l_total'],\n",
    "            \"T_bounded_w_total\": dic_entry_record['T_bounded_w_total'],\n",
    "            \"T_bounded_s_total\": dic_entry_record['T_bounded_s_total'],\n",
    "            \"T_net_extra\": dic_entry_record['T_net_extra'],\n",
    "            \"T_error_total\": dic_entry_record['T_error_total'],\n",
    "            \"T_interrupt_total\": dic_entry_record['T_interrupt_total'],\n",
    "            \"T_event_total\": dic_entry_record['T_event_total'],\n",
    "\n",
    "            \"N_bounded_l_total\": dic_entry_record['N_bounded_l_total'],\n",
    "            \"N_bounded_w_total\": dic_entry_record['N_bounded_w_total'], \n",
    "            \"N_bounded_s_total\": dic_entry_record['N_bounded_s_total'], \n",
    "            \"N_bounded_total\": dic_entry_record['N_bounded_total'],\n",
    "\n",
    "            \"KS_total\": dic_entry_record['KS_total'],\n",
    "            \"KS_type_total\": dic_entry_record['KS_type_total'],\n",
    "            \"KS_select_total\": dic_entry_record['KS_select_total'],\n",
    "            \"KS_bounded_l_total\": dic_entry_record['KS_bounded_l_total'],\n",
    "            \"KS_bounded_w_total\": dic_entry_record['KS_bounded_w_total'],\n",
    "            \"KS_bounded_s_total\": dic_entry_record['KS_bounded_s_total'],\n",
    "            \"KS_error_total\": dic_entry_record['KS_error_total'],\n",
    "            \"KS_interrupt_total\": dic_entry_record['KS_interrupt_total'],\n",
    "\n",
    "            # basic statistics\n",
    "            \"entry_rate\": float(len(sample)/T_total)*12.0, # wpm\n",
    "            # \"effective_entry_rate\":\n",
    "            \"net_entry_rate\": float((len(sample)/T_total)*12.0 - (12.0/T_key)), # wpm\n",
    "            # \"net_effective_entry_rate\":\n",
    "            \"KS_saving\": float(float(len(sample)) - KS_total),\n",
    "            \"KS_saving_rate\": float(float(len(sample)) - KS_total)/float(len(sample)) # %\n",
    "        }\n",
    "\n",
    "        data_dic_list.append(data_dic)\n",
    "\n",
    "    # data_dic_list.sort(key=sort_by_sentence_length)\n",
    "\n",
    "    # Collect data\n",
    "    df_data_dic_list = pd.DataFrame(data=data_dic_list)\n",
    "\n",
    "    return df_data_dic_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load fixed parameters for AAC users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User profile\n",
    "T_key =  0.6 # 0.26 # 0.6\n",
    "T_react_w = 1.20 # 0.45 # 1.20\n",
    "T_react_s = 5.08 # 1.90 # T_react_w * L_s_ave = 1.20*4.23 = 5.08\n",
    "\n",
    "# Word prediction settings\n",
    "P_pred_w_c = 0.6 # KWickChat\n",
    "P_pred_w_n = 0.5 # KWickChat\n",
    "\n",
    "# Sentence prediction settings\n",
    "def P_pred_s(current_word_index, L_s): # the probability of the system have correct sentence predictions\n",
    "    a=1\n",
    "    b=L_s\n",
    "    x=current_word_index\n",
    "    c=0\n",
    "    return a*math.log(x+1,b)+c\n",
    "\n",
    "# Text entering strategy\n",
    "L_min_w = 5 # 2-10\n",
    "k_look_w = 1\n",
    "p_max_w = 6\n",
    "\n",
    "L_min_s = 5 # 2-10\n",
    "k_look_s = 1\n",
    "p_max_s = 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condition AD - exp_2: L_min_w & L_min_s with BE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condition AD: Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human factors\n",
    "R_rational = 0.8 # 0.1~1\n",
    "R_error = 0.3 # 0~0.5\n",
    "R_interrupt = 0.2\n",
    "\n",
    "T_event = 5\n",
    "\n",
    "def T_interrupt(T_event): # the probability of the system have correct sentence predictions\n",
    "    a=0.189\n",
    "    c=1.03\n",
    "    return a*math.log(T_event)+c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compare_exp_2_condition_AD_all_data(condition):\n",
    "    # condition = \"AD\"\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(0,1.05,0.05):\n",
    "        for j in np.arange(0,1.05,0.05):\n",
    "            data_frame = Run_exp_2(SAMPLE_SIZE=100, CONDITION=condition, R_rational=i, R_error=j, R_interrupt=0.2, T_event=5, L_min_w=L_min_w, k_look_w=k_look_w, p_max_w=p_max_w, L_min_s=L_min_s, k_look_s=k_look_s, p_max_s=p_max_s)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'experiment_2_{condition}.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compare_exp_2_condition_AD_ideal(condition):\n",
    "    # condition = \"AD\"\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(2,10.1,0.1):\n",
    "        for j in np.arange(2,10.1,0.1):\n",
    "            data_frame = Run_exp_2(SAMPLE_SIZE=100, CONDITION=condition, R_rational=R_rational, R_error=R_error, R_interrupt=R_interrupt, T_event=5, L_min_w=i, k_look_w=k_look_w, p_max_w=p_max_w, L_min_s=j, k_look_s=k_look_s, p_max_s=p_max_s)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'experiment_2_{condition}.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOL_PRINT = False\n",
    "con_ad_df_exp_results = Compare_exp_2_condition_AD_all_data('best_AD_BEI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_rational = 1\n",
    "R_error = 0\n",
    "R_interrupt = 0\n",
    "\n",
    "BOOL_PRINT = False\n",
    "con_ad_df_exp_results_ideal = Compare_exp_2_condition_AD_ideal('AD_BEI_ideal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condition AD: Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "condition = 'best_AD_BEI'\n",
    "readname = f'experiment_2_{condition}.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "exp_2_con_ad_df_results_bei_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "condition = 'AD_BEI_ideal'\n",
    "readname = f'experiment_2_{condition}.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "exp_2_con_ad_df_results_bei_ideal_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### R_rational & R_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_rate = exp_2_con_ad_df_results_bei_csv[['net_entry_rate', 'R_rational', 'R_error']]\n",
    "\n",
    "entry_rate_mean = entry_rate.groupby(['R_rational', 'R_error']).mean()\n",
    "entry_rate_mean = entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = entry_rate_mean.pivot('R_rational', 'R_error', 'net_entry_rate')\n",
    "plt.xlabel('R_error (%)', size=15)\n",
    "plt.ylabel('R_rational (%)', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.4,y_stddev=.4)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,5))\n",
    "xticks = np.linspace(0, 100, 5, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,5))\n",
    "yticks = np.linspace(0, 100, 5, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "plt.colorbar()\n",
    "\n",
    "# Save data\n",
    "outname = f'exp2_B_E_ner.csv'\n",
    "outdir = './experiment_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "fullname = os.path.join(outdir, outname) \n",
    "pivot_table.to_csv(fullname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_rate = exp_2_con_ad_df_results_bei_csv[['KS_saving_rate', 'R_rational', 'R_error']]\n",
    "\n",
    "entry_rate_mean = entry_rate.groupby(['R_rational', 'R_error']).mean()\n",
    "entry_rate_mean = entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = entry_rate_mean.pivot('R_rational', 'R_error', 'KS_saving_rate')\n",
    "plt.xlabel('R_error (%)', size=15)\n",
    "plt.ylabel('R_rational (%)', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.4,y_stddev=.4)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,5))\n",
    "xticks = np.linspace(0, 100, 5, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,5))\n",
    "yticks = np.linspace(0, 100, 5, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.yaxis.set_major_formatter(PercentFormatter(1, 0))\n",
    "\n",
    "# # Save data\n",
    "# outname = f'exp2_B_E_ner.csv'\n",
    "# outdir = './experiment_result'\n",
    "# if not os.path.exists(outdir):\n",
    "#     os.mkdir(outdir)\n",
    "# fullname = os.path.join(outdir, outname) \n",
    "# pivot_table.to_csv(fullname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### L_min_s & L_min_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and k_look_w\n",
    "\n",
    "entry_rate = exp_2_con_ad_df_results_bei_ideal_csv[['net_entry_rate', 'L_min_w', 'L_min_s']]\n",
    "entry_rate_mean = entry_rate.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "entry_rate_mean = entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = entry_rate_mean.pivot('L_min_w', 'L_min_s', 'net_entry_rate')\n",
    "plt.xlabel('L_min_s', size=15)\n",
    "plt.ylabel('L_min_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.5,y_stddev=.5)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and k_look_w\n",
    "entry_rate = exp_1_con_ad_df_results_csv[['net_entry_rate', 'L_min_w', 'L_min_s']]\n",
    "entry_rate_mean = entry_rate.groupby(['L_min_w', 'L_min_s']).std()\n",
    "entry_rate_mean = entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = entry_rate_mean.pivot('L_min_w', 'L_min_s', 'net_entry_rate')\n",
    "plt.xlabel('L_min_w', size=15)\n",
    "plt.ylabel('L_min_s', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.4,y_stddev=.4)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s\n",
    "KS_saving_rate = exp_1_con_ad_df_results_csv[['KS_saving_rate', 'L_min_w', 'L_min_s']]\n",
    "KS_saving_rate_mean = KS_saving_rate.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "KS_saving_rate_mean = KS_saving_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = KS_saving_rate_mean.pivot('L_min_w', 'L_min_s', 'KS_saving_rate')\n",
    "plt.xlabel('L_min_w', size=15)\n",
    "plt.ylabel('L_min_s', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.4,y_stddev=.4)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cb.get_ticks()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s\n",
    "KS_saving_rate = exp_1_con_ad_df_results_csv[['KS_saving_rate', 'L_min_w', 'L_min_s']]\n",
    "KS_saving_rate_mean = KS_saving_rate.groupby(['L_min_w', 'L_min_s']).std()\n",
    "KS_saving_rate_mean = KS_saving_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = KS_saving_rate_mean.pivot('L_min_w', 'L_min_s', 'KS_saving_rate')\n",
    "plt.xlabel('L_min_w', size=15)\n",
    "plt.ylabel('L_min_s', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.4,y_stddev=.4)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "cb = plt.colorbar()\n",
    "# cb.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cb.get_ticks()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### net_entry_rate & sentence_length_in_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate net_entry_rate and sentence_length_in_words\n",
    "con_ad_net_entry_rate_L_min_s_k_look_s = exp_1_con_ad_df_results_csv[['net_entry_rate', 'L_min_s', 'sentence_length_in_words']] # _in_words\n",
    "con_ad_net_entry_rate_mean_L_min_s = con_ad_net_entry_rate_L_min_s_k_look_s.groupby(['L_min_s', 'sentence_length_in_words']).mean()\n",
    "vis_net_entry_rate_mean = con_ad_net_entry_rate_mean_L_min_s.groupby(['sentence_length_in_words']).mean()\n",
    "# vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "# pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'sentence_length', 'net_entry_rate')\n",
    "plt.xlabel('sentence_length_in_words', size=15)\n",
    "plt.ylabel('net_entry_rate_mean', size=15)\n",
    "plt.plot(vis_net_entry_rate_mean)\n",
    "plt.axhline(y=0, color='k', linestyle='--')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare difference between KLM and KLM-BE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_1_entry_rate = exp_1_con_ad_df_results_csv[['L_min_w', 'L_min_s', 'entry_rate']]\n",
    "exp_2_entry_rate = exp_2_con_ad_df_results_csv[['L_min_w', 'L_min_s', 'entry_rate']]\n",
    "\n",
    "diff_entry_rate = exp_1_entry_rate.rename(columns={'entry_rate': 'entry_rate_1'})\n",
    "diff_entry_rate['entry_rate_2'] = exp_2_entry_rate['entry_rate']\n",
    "diff_entry_rate['entry_rate_diff'] = diff_entry_rate['entry_rate_2'].subtract(diff_entry_rate['entry_rate_1'])\n",
    "diff_entry_rate = diff_entry_rate[['L_min_w', 'L_min_s', 'entry_rate_diff']]\n",
    "\n",
    "diff_entry_rate_mean = diff_entry_rate.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "diff_entry_rate_mean = diff_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = diff_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'entry_rate_diff')\n",
    "plt.xlabel('L_min_w', size=15)\n",
    "plt.ylabel('L_min_s', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.4,y_stddev=.4)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "plt.colorbar()\n",
    "\n",
    "diff_entry_rate_std = diff_entry_rate.groupby(['L_min_w', 'L_min_s']).std()\n",
    "diff_entry_rate_std = diff_entry_rate_std.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = diff_entry_rate_std.pivot('L_min_w', 'L_min_s', 'entry_rate_diff')\n",
    "plt.xlabel('L_min_w', size=15)\n",
    "plt.ylabel('L_min_s', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.4,y_stddev=.4)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "plt.colorbar()\n",
    "\n",
    "\n",
    "# print(diff_entry_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How R_rational influence the entry rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sort_by_sentence_length(e):\n",
    "#     return e[\"sentence_length_in_words\"]\n",
    "    \n",
    "def Run_exp_3(SAMPLE_SIZE, CONDITION, L_min_w=100.0, k_look_w=0.0, p_max_w=0.0, L_min_s=100.0, k_look_s=0.0, p_max_s=0.0):\n",
    "    with open(f'aac_daily_conversation_sample_{SAMPLE_SIZE}.txt') as file:\n",
    "        samples = file.readlines()\n",
    "    # samples = [\"Oh so what did dad have to say to you?\"]\n",
    "    data_dic_list = []\n",
    "\n",
    "    for i, s in enumerate(samples):\n",
    "        # print(f\"In sample {i}/{len(samples)}: {s}\")\n",
    "        sample = s.strip()\n",
    "        sample = re.sub(r'[^\\w\\s]', '', sample)\n",
    "        word_list = sample.split(' ')\n",
    "        dic_entry_record, T_total, KS_total = Type_one_sentence(sample, L_min_w, k_look_w, p_max_w, L_min_s, k_look_s, p_max_s) # Take_average_of_one_sentence_result(1, sample)\n",
    "        data_dic = {\n",
    "            # settings\n",
    "            \"L_min_w\": float(L_min_w),\n",
    "            \"k_look_w\": float(k_look_w),\n",
    "            \"p_max_w\": float(p_max_w),\n",
    "            \"L_min_s\": float(L_min_s),\n",
    "            \"k_look_s\": float(k_look_s),\n",
    "            \"p_max_s\": float(p_max_s),\n",
    "            \"P_pred_w_c\": float(P_pred_w_c),\n",
    "            \"P_pred_w_n\": float(P_pred_w_n),\n",
    "            \"T_key\": float(T_key),\n",
    "            \"T_react_w\": float(T_react_w),\n",
    "            \"T_react_s\": float(T_react_s),\n",
    "            \"R_rational\": float(R_rational), # bounded rationality index\n",
    "            \"R_error\": float(R_error), # human error rate\n",
    "            \"R_interrupt\": float(R_interrupt), # interruption rate\n",
    "            \"T_event\": float(T_event), # interruption time\n",
    "\n",
    "            # results\n",
    "            \"sentence\": sample,\n",
    "            \"sentence_length\": int(len(sample)),\n",
    "            \"sentence_length_in_words\": int(len(word_list)),\n",
    "\n",
    "            \"T_total\": dic_entry_record['T_total'],\n",
    "            \"T_key_total\": dic_entry_record['T_key_total'],\n",
    "            \"T_react_w_total\": dic_entry_record['T_react_w_total'],\n",
    "            \"T_react_s_total\": dic_entry_record['T_react_s_total'],\n",
    "            \"T_react_total\": dic_entry_record['T_react_total'],\n",
    "            \"T_bounded_l_total\": dic_entry_record['T_bounded_l_total'],\n",
    "            \"T_bounded_w_total\": dic_entry_record['T_bounded_w_total'],\n",
    "            \"T_bounded_s_total\": dic_entry_record['T_bounded_s_total'],\n",
    "            \"T_error_total\": dic_entry_record['T_error_total'],\n",
    "            \"T_interrupt_total\": dic_entry_record['T_interrupt_total'],\n",
    "\n",
    "            \"T_event_total\": dic_entry_record['T_event_total'],\n",
    "            \"N_bounded_l_total\": dic_entry_record['N_bounded_l_total'],\n",
    "            \"N_bounded_w_total\": dic_entry_record['N_bounded_w_total'], \n",
    "            \"N_bounded_s_total\": dic_entry_record['N_bounded_s_total'], \n",
    "            \"N_bounded_total\": dic_entry_record['N_bounded_total'],\n",
    "\n",
    "            \"KS_total\": dic_entry_record['KS_total'],\n",
    "            \"KS_type_total\": dic_entry_record['KS_type_total'],\n",
    "            \"KS_select_total\": dic_entry_record['KS_select_total'],\n",
    "            \"KS_bounded_l_total\": dic_entry_record['KS_bounded_l_total'],\n",
    "            \"KS_bounded_w_total\": dic_entry_record['KS_bounded_w_total'],\n",
    "            \"KS_bounded_s_total\": dic_entry_record['KS_bounded_s_total'],\n",
    "            \"KS_error_total\": dic_entry_record['KS_error_total'],\n",
    "            \"KS_interrupt_total\": dic_entry_record['KS_interrupt_total'],\n",
    "\n",
    "            # basic statistics\n",
    "            \"entry_rate\": float(len(sample)/T_total)*12.0, # wpm\n",
    "            # \"effective_entry_rate\":\n",
    "            \"net_entry_rate\": float((len(sample)/T_total)*12.0 - (12.0/T_key)), # wpm\n",
    "            # \"net_effective_entry_rate\":\n",
    "            \"KS_saving\": float(float(len(sample)) - KS_total),\n",
    "            \"KS_saving_rate\": float(float(len(sample)) - KS_total)/float(len(sample)) # %\n",
    "        }\n",
    "\n",
    "        data_dic_list.append(data_dic)\n",
    "\n",
    "    # data_dic_list.sort(key=sort_by_sentence_length)\n",
    "\n",
    "    # Collect data\n",
    "    df_data_dic_list = pd.DataFrame(data=data_dic_list)\n",
    "\n",
    "    return df_data_dic_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Simulate imperfect user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load fundamental function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Run_exp_3(SAMPLE_SIZE, CONDITION, L_min_w=100.0, k_look_w=0.0, p_max_w=0.0, L_min_s=100.0, k_look_s=0.0, p_max_s=0.0, R_rational=1.0, R_error=0.0, R_interrupt=0.0, T_event=5.0):\n",
    "    with open(f'aac_daily_conversation_sample_{SAMPLE_SIZE}.txt') as file:\n",
    "        samples = file.readlines()\n",
    "    # samples = [\"Oh so what did dad have to say to you?\"]\n",
    "    data_dic_list = []\n",
    "\n",
    "    for i, s in enumerate(samples):\n",
    "        # print(f\"In sample {i}/{len(samples)}: {s}\")\n",
    "        sample = s.strip()\n",
    "        sample = re.sub(r'[^\\w\\s]', '', sample)\n",
    "        word_list = sample.split(' ')\n",
    "        dic_entry_record, T_total, KS_total = Type_one_sentence(sample, L_min_w, k_look_w, p_max_w, L_min_s, k_look_s, p_max_s, R_rational, R_error, R_interrupt, T_event) # Take_average_of_one_sentence_result(1, sample)\n",
    "\n",
    "        data_dic = {\n",
    "            # settings\n",
    "            \"L_min_w\": float(L_min_w),\n",
    "            \"k_look_w\": float(k_look_w),\n",
    "            \"p_max_w\": float(p_max_w),\n",
    "            \"L_min_s\": float(L_min_s),\n",
    "            \"k_look_s\": float(k_look_s),\n",
    "            \"p_max_s\": float(p_max_s),\n",
    "            \"P_pred_w_c\": float(P_pred_w_c),\n",
    "            \"P_pred_w_n\": float(P_pred_w_n),\n",
    "            \"T_key\": float(T_key),\n",
    "            \"T_react_w\": float(T_react_w),\n",
    "            \"T_react_s\": float(T_react_s),\n",
    "            \"R_rational\": float(R_rational), # bounded rationality index\n",
    "            \"R_error\": float(R_error), # human error rate\n",
    "            \"R_interrupt\": float(R_interrupt), # interruption rate\n",
    "            \"T_event\": float(T_event), # interruption time\n",
    "\n",
    "            # results\n",
    "            \"sentence\": sample,\n",
    "            \"sentence_length\": int(len(sample)),\n",
    "            \"sentence_length_in_words\": int(len(word_list)),\n",
    "\n",
    "            # T: \n",
    "            \"T_total\": dic_entry_record['T_total'],\n",
    "            \"T_key_total\": dic_entry_record['T_key_total'],\n",
    "            \"T_react_w_total\": dic_entry_record['T_react_w_total'],\n",
    "            \"T_react_s_total\": dic_entry_record['T_react_s_total'],\n",
    "            \"T_react_total\": dic_entry_record['T_react_total'],\n",
    "            # bounded rationality\n",
    "            \"T_extra_total\": dic_entry_record['T_extra_total'],\n",
    "            \"T_extra_s\": dic_entry_record['T_extra_s'],\n",
    "            \"T_extra_w\": dic_entry_record['T_extra_w'],\n",
    "            \"T_extra_l\": dic_entry_record['T_extra_l'],\n",
    "            \"T_net_extra\": dic_entry_record['T_net_extra'],\n",
    "            # human error\n",
    "            \"T_error_total\": dic_entry_record['T_error_total'],       \n",
    "            # interruption\n",
    "            \"T_interrupt_total\": dic_entry_record['T_interrupt_total'],\n",
    "            \"T_event_total\": dic_entry_record['T_event_total'],\n",
    "\n",
    "            # KS: \n",
    "            \"KS_total\": dic_entry_record['KS_total'],\n",
    "            \"KS_type_total\": dic_entry_record['KS_type_total'],\n",
    "            \"KS_select_total\": dic_entry_record['KS_select_total'],\n",
    "            # bounded rationality\n",
    "            \"KS_extra_total\": dic_entry_record['KS_extra_total'],\n",
    "            \"KS_extra_s\": dic_entry_record['KS_extra_s'],\n",
    "            \"KS_extra_w\": dic_entry_record['KS_extra_w'],\n",
    "            \"KS_extra_l\": dic_entry_record['KS_extra_l'],\n",
    "            # human error\n",
    "            \"KS_error_total\": dic_entry_record['KS_error_total'],\n",
    "            # interruption no KS\n",
    "\n",
    "            # basic statistics\n",
    "            \"entry_rate\": float(len(sample)/T_total)*12.0, # wpm\n",
    "            \"net_entry_rate\": float((len(sample)/T_total)*12.0 - (12.0/T_key)), # wpm\n",
    "            \"KS_saving\": float(float(len(sample)) - KS_total),\n",
    "            \"KS_saving_rate\": float(float(len(sample)) - KS_total)/float(len(sample)), # %\n",
    "\n",
    "            # Human performance analyses\n",
    "            \"effective_typing_rate_index\": float(  ((dic_entry_record['KS_total']-dic_entry_record['KS_error_total'])/dic_entry_record['T_key_total']) * T_key ),\n",
    "            \"error_index\": float(dic_entry_record['KS_error_total']/(dic_entry_record['KS_total']-dic_entry_record['KS_extra_total'])),\n",
    "            \"rational_index\": float(1- ( dic_entry_record['KS_extra_total']/(dic_entry_record['KS_total']-dic_entry_record['KS_error_total']) ) ),\n",
    "            \"intuitiveness_index_KS\": float(1- ( (dic_entry_record['KS_error_total']+dic_entry_record['KS_extra_total'])/dic_entry_record['KS_total'] ) ),\n",
    "            \"intuitiveness_index_T\": float(1- ( (dic_entry_record['T_error_total']+dic_entry_record['T_net_extra'])/dic_entry_record['T_total'] ) )\n",
    "        }\n",
    "\n",
    "        data_dic_list.append(data_dic)\n",
    "\n",
    "    # data_dic_list.sort(key=sort_by_sentence_length)\n",
    "\n",
    "    # Collect data\n",
    "    df_data_dic_list = pd.DataFrame(data=data_dic_list)\n",
    "\n",
    "    return df_data_dic_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load fixed parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User profile\n",
    "T_key =  0.26 # 0.26 # 0.6\n",
    "T_react_w = 0.45 # 0.45 # 1.20\n",
    "T_react_s = 1.90 # T_react_w * L_s_ave = 1.20*4.23 = 5.08\n",
    "\n",
    "# Word prediction settings\n",
    "P_pred_w_c = 0.6 # 0.6 # KWickChat\n",
    "P_pred_w_n = 0.5 # 0.5 # KWickChat\n",
    "\n",
    "# Sentence prediction settings\n",
    "def P_pred_s(current_word_index, L_s): # the probability of the system have correct sentence predictions\n",
    "    a=1\n",
    "    b=L_s\n",
    "    x=current_word_index\n",
    "    c=0\n",
    "    return a*math.log(x+1,b)+c\n",
    "\n",
    "L_min_w = 5\n",
    "k_look_w = 1 \n",
    "p_max_w = 6 \n",
    "L_min_s = 5 \n",
    "k_look_s = 1 \n",
    "p_max_s = 6\n",
    "\n",
    "# Human factors\n",
    "R_rational = 1 #0.7 # 0.1~1\n",
    "R_error = 0 #0.4 # 0~0.5\n",
    "R_interrupt = 0 #0.2\n",
    "\n",
    "T_event = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution: L_min_w & L_min_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Simulate_imperfect_user(condition):\n",
    "    # condition = \"AD\"\n",
    "    exp_result_dic_list = []\n",
    "    for i in np.arange(2,10.1,0.1):\n",
    "        for j in np.arange(2,10.1,0.1):\n",
    "            data_frame = Run_exp_3(SAMPLE_SIZE=100, CONDITION=condition, R_rational=R_rational, R_error=R_error, R_interrupt=R_interrupt, T_event=T_event, L_min_w=i, k_look_w=k_look_w, p_max_w=p_max_w, L_min_s=j, k_look_s=k_look_s, p_max_s=p_max_s)\n",
    "            exp_result_dic_list.append(data_frame)\n",
    "            \n",
    "    exp_results = [df for df in exp_result_dic_list]\n",
    "    df_exp_results = pd.concat(exp_results, ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    outname = f'experiment_3_{condition}.csv'\n",
    "    outdir = './experiment_result'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    df_exp_results.to_csv(fullname)\n",
    "            \n",
    "    return df_exp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ideal: Human factors\n",
    "R_rational = 1 #0.7 # 0.1~1\n",
    "R_error = 0 #0.3 # 0~0.5\n",
    "R_interrupt = 0\n",
    "\n",
    "BOOL_PRINT = False\n",
    "exp_3_con_ad_df_exp_results_ideal = Simulate_imperfect_user('AD_ideal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_rational = 1 #0.7 # 0.1~1\n",
    "R_error = 0 #0.3 # 0~0.5\n",
    "R_interrupt = 0.5 \n",
    "\n",
    "T_event = 5\n",
    "\n",
    "BOOL_PRINT = False\n",
    "exp_3_con_ad_df_exp_results_surrogate = Simulate_imperfect_user('AD_surrogate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "condition = 'AD_ideal'\n",
    "readname = f'experiment_3_{condition}.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "exp_3_con_ad_df_results_ideal_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "condition = 'AD_surrogate'\n",
    "readname = f'experiment_3_{condition}.csv'\n",
    "readdir = './experiment_result'\n",
    "fullname = os.path.join(readdir, readname)\n",
    "exp_3_con_ad_df_results_surrogate_csv = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L_min_w & L_min_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s\n",
    "con_ad_net_entry_rate_L_min_w_L_min_s = exp_3_con_ad_df_results_surrogate_csv[['effective_typing_rate_index', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = con_ad_net_entry_rate_L_min_w_L_min_s.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'effective_typing_rate_index')\n",
    "plt.xlabel('L_min_s', size=15)\n",
    "plt.ylabel('L_min_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.5,y_stddev=.5)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cb.get_ticks()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ideal: effective_typing_rate_index\n",
    "con_ad_net_entry_rate_L_min_w_L_min_s = exp_3_con_ad_df_results_ideal_csv[['effective_typing_rate_index', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = con_ad_net_entry_rate_L_min_w_L_min_s.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'effective_typing_rate_index')\n",
    "plt.xlabel('L_min_s', size=15)\n",
    "plt.ylabel('L_min_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.5,y_stddev=.5)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cb.get_ticks()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s\n",
    "con_ad_net_entry_rate_L_min_w_L_min_s = exp_3_con_ad_df_results_surrogate_csv[['effective_typing_rate_index', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = con_ad_net_entry_rate_L_min_w_L_min_s.groupby(['L_min_w', 'L_min_s']).std()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'effective_typing_rate_index')\n",
    "plt.xlabel('L_min_s', size=15)\n",
    "plt.ylabel('L_min_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.5,y_stddev=.5)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cb.get_ticks()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s\n",
    "con_ad_net_entry_rate_L_min_w_L_min_s = exp_3_con_ad_df_results_surrogate_csv[['net_entry_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = con_ad_net_entry_rate_L_min_w_L_min_s.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'net_entry_rate')\n",
    "plt.xlabel('L_min_s', size=15)\n",
    "plt.ylabel('L_min_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.5,y_stddev=.5)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ideal: net_entry_rate\n",
    "con_ad_net_entry_rate_L_min_w_L_min_s = exp_3_con_ad_df_results_ideal_csv[['net_entry_rate', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = con_ad_net_entry_rate_L_min_w_L_min_s.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'net_entry_rate')\n",
    "plt.xlabel('L_min_s', size=15)\n",
    "plt.ylabel('L_min_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.5,y_stddev=.5)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "cb = plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KS_error_total: L_min_w and L_min_s\n",
    "KS_error_total = exp_3_con_ad_df_results_surrogate_csv[['KS_error_total', 'L_min_w', 'L_min_s']]\n",
    "KS_error_total_mean = KS_error_total.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "KS_error_total_mean = KS_error_total_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = KS_error_total_mean.pivot('L_min_w', 'L_min_s', 'KS_error_total')\n",
    "plt.xlabel('L_min_s', size=15)\n",
    "plt.ylabel('L_min_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.5,y_stddev=.5)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KS_extra_total: L_min_w and L_min_s\n",
    "KS_extra_total = exp_3_con_ad_df_results_surrogate_csv[['KS_extra_total', 'L_min_w', 'L_min_s']]\n",
    "KS_extra_total_mean = KS_extra_total.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "KS_extra_total_mean = KS_extra_total_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = KS_extra_total_mean.pivot('L_min_w', 'L_min_s', 'KS_extra_total')\n",
    "plt.xlabel('L_min_s', size=15)\n",
    "plt.ylabel('L_min_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.5,y_stddev=.5)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T_net_extra: L_min_w and L_min_s\n",
    "con_ad_net_entry_rate_L_min_w_L_min_s = exp_3_con_ad_df_results_surrogate_csv[['T_net_extra', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = con_ad_net_entry_rate_L_min_w_L_min_s.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'T_net_extra')\n",
    "plt.xlabel('L_min_s', size=15)\n",
    "plt.ylabel('L_min_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.5,y_stddev=.5)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rationality index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rational_index: L_min_w and L_min_s\n",
    "con_ad_net_entry_rate_L_min_w_L_min_s = exp_3_con_ad_df_results_surrogate_csv[['rational_index', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = con_ad_net_entry_rate_L_min_w_L_min_s.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'rational_index')\n",
    "plt.xlabel('L_min_s', size=15)\n",
    "plt.ylabel('L_min_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.5,y_stddev=.5)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cb.get_ticks()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Error index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error_index: L_min_w and L_min_s\n",
    "con_ad_net_entry_rate_L_min_w_L_min_s = exp_3_con_ad_df_results_surrogate_csv[['error_index', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = con_ad_net_entry_rate_L_min_w_L_min_s.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'error_index')\n",
    "plt.xlabel('L_min_s', size=15)\n",
    "plt.ylabel('L_min_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.5,y_stddev=.5)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cb.get_ticks()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Intuitive index KS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s\n",
    "con_ad_net_entry_rate_L_min_w_L_min_s = exp_3_con_ad_df_results_surrogate_csv[['intuitiveness_index_KS', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = con_ad_net_entry_rate_L_min_w_L_min_s.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'intuitiveness_index_KS')\n",
    "plt.xlabel('L_min_s', size=15)\n",
    "plt.ylabel('L_min_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.5,y_stddev=.5)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cb.get_ticks()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Intuitive index T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate L_min_w and L_min_s\n",
    "con_ad_net_entry_rate_L_min_w_L_min_s = exp_3_con_ad_df_results_surrogate_csv[['intuitiveness_index_T', 'L_min_w', 'L_min_s']]\n",
    "vis_net_entry_rate_mean = con_ad_net_entry_rate_L_min_w_L_min_s.groupby(['L_min_w', 'L_min_s']).mean()\n",
    "vis_net_entry_rate_mean = vis_net_entry_rate_mean.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pivot_table = vis_net_entry_rate_mean.pivot('L_min_w', 'L_min_s', 'intuitiveness_index_T')\n",
    "plt.xlabel('L_min_s', size=15)\n",
    "plt.ylabel('L_min_w', size=15)\n",
    "plt.imshow(pivot_table, cmap='coolwarm', interpolation='nearest')\n",
    "# plt.imshow(convolve(pivot_table, Gaussian2DKernel(x_stddev=.5,y_stddev=.5)), cmap='coolwarm', interpolation='nearest')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks(np.arange(0,pivot_table.columns.size+1,10))\n",
    "xticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_xticklabels(xticks)\n",
    "ax.set_yticks(np.arange(0,pivot_table.index.size+1,10))\n",
    "yticks = np.linspace(2, 10, 9, dtype=np.int16)\n",
    "ax.set_yticklabels(yticks)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.set_yticklabels([\"{:.1%}\".format(i) for i in cb.get_ticks()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9241274ca8a61782360502ec0b716a12170700aa1f7bef6ba801933f15227c88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
